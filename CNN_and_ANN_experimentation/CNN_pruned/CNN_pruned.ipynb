{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_pruned.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMUaHUISfCFlz2NLofViXbb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Worksapce set up**"],"metadata":{"id":"QyrvJeAiRZoj"}},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGvumalrRRTA","executionInfo":{"status":"ok","timestamp":1656653982456,"user_tz":240,"elapsed":1150,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"32d2c83a-b0d3-43f0-9dff-59d05da90532"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["# Connecting to google drive\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["# Import libraries\n","%pylab inline\n","!pip install -q tensorflow-model-optimization\n","\n","import tensorflow as tf\n","import tensorflow_model_optimization as tfmot\n","from tensorflow.keras.optimizers import SGD\n","import numpy as np\n","import tempfile\n","import zipfile\n","import os"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oe3MFNYHRqv7","executionInfo":{"status":"ok","timestamp":1656653986755,"user_tz":240,"elapsed":4303,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"0c23126c-864e-4b89-cda3-416b8dde098d"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Populating the interactive namespace from numpy and matplotlib\n"]}]},{"cell_type":"code","source":["# Display python and library versions\n","!python --versions\n","print('Numpy ' + np.__version__)\n","print('TensorFlow ' + tf.__version__)\n","print('Keras ' + tf.keras.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tw-wwDB0Rw3n","executionInfo":{"status":"ok","timestamp":1656653986931,"user_tz":240,"elapsed":185,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"7666a262-92e4-4bfb-c9fc-31d2f68372de"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["unknown option --versions\n","usage: python3 [option] ... [-c cmd | -m mod | file | -] [arg] ...\n","Try `python -h' for more information.\n","Numpy 1.21.6\n","TensorFlow 2.8.2\n","Keras 2.8.0\n"]}]},{"cell_type":"markdown","source":["# **Dataset Management**"],"metadata":{"id":"Q5hDYa2PSWRK"}},{"cell_type":"code","source":["# Loads the data and splits it into 60% training and 40% testing sets\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","y_test_old = y_test\n","\n","x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n","x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0\n","\n","y_train = tf.keras.utils.to_categorical(y_train)\n","y_test = tf.keras.utils.to_categorical(y_test)\n","\n","x_train = x_train[0:6000]\n","x_test = x_test[0:1000]\n","y_train = y_train[0:6000]\n","y_test = y_test[0:1000]"],"metadata":{"id":"TSAspn8HSUjC","executionInfo":{"status":"ok","timestamp":1656653987475,"user_tz":240,"elapsed":550,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["# **Clustering**"],"metadata":{"id":"CFrmpkLsSsWD"}},{"cell_type":"code","source":["# Loads the base model for ANN tests and gets baseline accuracy for result comparison\n","base_model = tf.keras.models.load_model('drive/MyDrive/GE_practicum/CNN_base')\n","base_model.fit(x_train,y_train,epochs = 10,validation_data = (x_test,y_test), batch_size=32)\n","base_model.summary()\n","\n","_, keras_file = tempfile.mkstemp('.h5')\n","tf.keras.models.save_model(base_model, keras_file, include_optimizer=False)\n","print('Saved baseline model to:', keras_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLu2bOK2SvKS","executionInfo":{"status":"ok","timestamp":1656654020346,"user_tz":240,"elapsed":32876,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"8e51f7a2-839c-4292-9730-00b6594c72dd"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","188/188 [==============================] - 4s 19ms/step - loss: 0.0231 - accuracy: 0.9952 - val_loss: 0.1039 - val_accuracy: 0.9610\n","Epoch 2/10\n","188/188 [==============================] - 4s 23ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.1150 - val_accuracy: 0.9640\n","Epoch 3/10\n","188/188 [==============================] - 5s 24ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.1139 - val_accuracy: 0.9640\n","Epoch 4/10\n","188/188 [==============================] - 5s 26ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.1203 - val_accuracy: 0.9600\n","Epoch 5/10\n","188/188 [==============================] - 3s 14ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.1058 - val_accuracy: 0.9640\n","Epoch 6/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.1256 - val_accuracy: 0.9630\n","Epoch 7/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.1134 - val_accuracy: 0.9590\n","Epoch 8/10\n","188/188 [==============================] - 2s 12ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.1172 - val_accuracy: 0.9610\n","Epoch 9/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.1167 - val_accuracy: 0.9600\n","Epoch 10/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.1168 - val_accuracy: 0.9650\n","Model: \"sequential_13\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_13 (Conv2D)          (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d_13 (MaxPoolin  (None, 8, 8, 32)         0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_13 (Flatten)        (None, 2048)              0         \n","                                                                 \n"," dense_26 (Dense)            (None, 30)                61470     \n","                                                                 \n"," dense_27 (Dense)            (None, 10)                310       \n","                                                                 \n","=================================================================\n","Total params: 62,100\n","Trainable params: 62,100\n","Non-trainable params: 0\n","_________________________________________________________________\n","Saved baseline model to: /tmp/tmph0pd192w.h5\n"]}]},{"cell_type":"code","source":["prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","\n","batch_size = 32\n","epochs = 10\n","\n","num_images = x_train.shape[0]\n","end_step = np.ceil(num_images / batch_size).astype(np.float32) * epochs\n","\n","pruning_params = {\n","      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n","                                                               final_sparsity=0.80,\n","                                                               begin_step=0,\n","                                                               end_step=end_step)\n","}\n","\n","pruned_model = prune_low_magnitude(base_model, **pruning_params)\n","\n","opt = SGD(learning_rate=0.0001, momentum=0.9)\n","pruned_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n","pruned_model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghrd390Tfpeg","executionInfo":{"status":"ok","timestamp":1656654020509,"user_tz":240,"elapsed":168,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"7771be83-ab70-46ff-e89b-0d23c1c06c65"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_13\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," prune_low_magnitude_conv2d_  (None, 26, 26, 32)       610       \n"," 13 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_max_poo  (None, 8, 8, 32)         1         \n"," ling2d_13 (PruneLowMagnitud                                     \n"," e)                                                              \n","                                                                 \n"," prune_low_magnitude_flatten  (None, 2048)             1         \n"," _13 (PruneLowMagnitude)                                         \n","                                                                 \n"," prune_low_magnitude_dense_2  (None, 30)               122912    \n"," 6 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_dense_2  (None, 10)               612       \n"," 7 (PruneLowMagnitude)                                           \n","                                                                 \n","=================================================================\n","Total params: 124,136\n","Trainable params: 62,100\n","Non-trainable params: 62,036\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  aggregation=tf.VariableAggregation.MEAN)\n","/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  aggregation=tf.VariableAggregation.MEAN)\n","/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  trainable=False)\n"]}]},{"cell_type":"code","source":["callbacks = [\n","  tfmot.sparsity.keras.UpdatePruningStep(),\n","]\n","\n","pruned_model.fit(x_train,y_train,epochs = epochs,validation_data = (x_test,y_test), batch_size=batch_size, callbacks=callbacks)\n","pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n","\n","_, pruned_keras_file = tempfile.mkstemp('.h5')\n","tf.keras.models.save_model(pruned_model, pruned_keras_file, include_optimizer=False)\n","print('Saved pruned Keras model to:', pruned_keras_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ipza72YNgFUZ","executionInfo":{"status":"ok","timestamp":1656654063247,"user_tz":240,"elapsed":42742,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"dcfec836-7d63-4fa5-a228-1efd83cd74e1"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","188/188 [==============================] - 4s 14ms/step - loss: 0.0551 - accuracy: 0.9832 - val_loss: 0.1939 - val_accuracy: 0.9390\n","Epoch 2/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.0596 - accuracy: 0.9847 - val_loss: 0.1696 - val_accuracy: 0.9410\n","Epoch 3/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.1136 - accuracy: 0.9612 - val_loss: 0.2166 - val_accuracy: 0.9260\n","Epoch 4/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.1824 - accuracy: 0.9427 - val_loss: 0.3130 - val_accuracy: 0.9010\n","Epoch 5/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2218 - accuracy: 0.9435 - val_loss: 0.3617 - val_accuracy: 0.8880\n","Epoch 6/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2533 - accuracy: 0.9347 - val_loss: 0.3773 - val_accuracy: 0.8900\n","Epoch 7/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2524 - accuracy: 0.9358 - val_loss: 0.3958 - val_accuracy: 0.8800\n","Epoch 8/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2627 - accuracy: 0.9348 - val_loss: 0.3782 - val_accuracy: 0.8840\n","Epoch 9/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2560 - accuracy: 0.9360 - val_loss: 0.3665 - val_accuracy: 0.8940\n","Epoch 10/10\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2333 - accuracy: 0.9467 - val_loss: 0.3368 - val_accuracy: 0.9010\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","Saved pruned Keras model to: /tmp/tmpu2g_c6hh.h5\n"]}]},{"cell_type":"markdown","source":["# **Quantization aware training**"],"metadata":{"id":"JKiU3cEnfepg"}},{"cell_type":"code","source":["quantize_model = tfmot.quantization.keras.quantize_model\n","model = quantize_model(pruned_model)\n","\n","opt = SGD(learning_rate=0.0001, momentum=0.9)\n","model.compile(optimizer = opt,loss = 'categorical_crossentropy' , metrics=['accuracy'])\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rkexQaL6eRP6","executionInfo":{"status":"ok","timestamp":1656654065115,"user_tz":240,"elapsed":1878,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"fb2f463a-97e9-451d-96a0-67fbf812ade0"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_13\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," quantize_layer (QuantizeLay  (None, 28, 28, 1)        3         \n"," er)                                                             \n","                                                                 \n"," quant_conv2d_13 (QuantizeWr  (None, 26, 26, 32)       387       \n"," apperV2)                                                        \n","                                                                 \n"," quant_max_pooling2d_13 (Qua  (None, 8, 8, 32)         1         \n"," ntizeWrapperV2)                                                 \n","                                                                 \n"," quant_flatten_13 (QuantizeW  (None, 2048)             1         \n"," rapperV2)                                                       \n","                                                                 \n"," quant_dense_26 (QuantizeWra  (None, 30)               61475     \n"," pperV2)                                                         \n","                                                                 \n"," quant_dense_27 (QuantizeWra  (None, 10)               315       \n"," pperV2)                                                         \n","                                                                 \n","=================================================================\n","Total params: 62,182\n","Trainable params: 62,100\n","Non-trainable params: 82\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Performs quantization aware training\n","model.fit(x_train,y_train,epochs = 10,validation_data = (x_test,y_test), batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RGj0_RSyjkyB","executionInfo":{"status":"ok","timestamp":1656654099813,"user_tz":240,"elapsed":34709,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"bf29f9c9-5f45-434d-913f-fd2cb29c1e28"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","188/188 [==============================] - 4s 19ms/step - loss: 0.2486 - accuracy: 0.9512 - val_loss: 0.3386 - val_accuracy: 0.9030\n","Epoch 2/10\n","188/188 [==============================] - 3s 18ms/step - loss: 0.2118 - accuracy: 0.9587 - val_loss: 0.3034 - val_accuracy: 0.9120\n","Epoch 3/10\n","188/188 [==============================] - 3s 18ms/step - loss: 0.1893 - accuracy: 0.9613 - val_loss: 0.2826 - val_accuracy: 0.9170\n","Epoch 4/10\n","188/188 [==============================] - 3s 18ms/step - loss: 0.1736 - accuracy: 0.9642 - val_loss: 0.2652 - val_accuracy: 0.9170\n","Epoch 5/10\n","188/188 [==============================] - 3s 18ms/step - loss: 0.1621 - accuracy: 0.9663 - val_loss: 0.2528 - val_accuracy: 0.9180\n","Epoch 6/10\n","188/188 [==============================] - 3s 18ms/step - loss: 0.1528 - accuracy: 0.9692 - val_loss: 0.2428 - val_accuracy: 0.9190\n","Epoch 7/10\n","188/188 [==============================] - 3s 18ms/step - loss: 0.1449 - accuracy: 0.9708 - val_loss: 0.2329 - val_accuracy: 0.9260\n","Epoch 8/10\n","188/188 [==============================] - 3s 18ms/step - loss: 0.1382 - accuracy: 0.9707 - val_loss: 0.2251 - val_accuracy: 0.9270\n","Epoch 9/10\n","188/188 [==============================] - 3s 18ms/step - loss: 0.1324 - accuracy: 0.9723 - val_loss: 0.2198 - val_accuracy: 0.9270\n","Epoch 10/10\n","188/188 [==============================] - 3s 18ms/step - loss: 0.1281 - accuracy: 0.9733 - val_loss: 0.2140 - val_accuracy: 0.9330\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3d3f779350>"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["# **Quantization and conversion to tflite**"],"metadata":{"id":"IW-berAamM7_"}},{"cell_type":"code","source":["# Conversion to tflite\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.target_spec.supported_ops = [\n","tf.lite.OpsSet.TFLITE_BUILTINS,\n","tf.lite.OpsSet.SELECT_TF_OPS\n","]\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_model = converter.convert()\n","\n","open('CNN_pruned.tflite', 'wb').write(tflite_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nmbbjt-OmbGY","executionInfo":{"status":"ok","timestamp":1656654102961,"user_tz":240,"elapsed":3152,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"4b279500-e5ae-49d6-d3b9-1803912eb49f"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as conv2d_13_layer_call_fn, conv2d_13_layer_call_and_return_conditional_losses, flatten_13_layer_call_fn, flatten_13_layer_call_and_return_conditional_losses, dense_26_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmp4nwnqzbw/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmp4nwnqzbw/assets\n","/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["66760"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# Check tflite model characteristics\n","tf.lite.experimental.Analyzer.analyze(model_content=tflite_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qioWLOMmtnS","executionInfo":{"status":"ok","timestamp":1656654102963,"user_tz":240,"elapsed":20,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"bae407fc-eded-452b-d1f1-82952c93d69a"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["=== TFLite ModelAnalyzer ===\n","\n","Your TFLite model has '1' subgraph(s). In the subgraph description below,\n","T# represents the Tensor numbers. For example, in Subgraph#0, the QUANTIZE op takes\n","tensor #0 as input and produces tensor #5 as output.\n","\n","Subgraph#0 main(T#0) -> [T#15]\n","  Op#0 QUANTIZE(T#0) -> [T#5]\n","  Op#1 CONV_2D(T#5, T#6, T#2) -> [T#7]\n","  Op#2 MAX_POOL_2D(T#7) -> [T#8]\n","  Op#3 RESHAPE(T#8, T#1) -> [T#9]\n","  Op#4 FULLY_CONNECTED(T#9, T#10, T#3) -> [T#11]\n","  Op#5 FULLY_CONNECTED(T#11, T#12, T#4) -> [T#13]\n","  Op#6 SOFTMAX(T#13) -> [T#14]\n","  Op#7 DEQUANTIZE(T#14) -> [T#15]\n","\n","Tensors of Subgraph#0\n","  T#0(serving_default_conv2d_13_input:0) shape_signature:[-1, 28, 28, 1], type:FLOAT32\n","  T#1(sequential_13/quant_flatten_13/Const) shape:[2], type:INT32 RO 8 bytes\n","  T#2(conv2d_13/bias) shape:[32], type:INT32 RO 128 bytes\n","  T#3(dense_26/bias) shape:[30], type:INT32 RO 120 bytes\n","  T#4(dense_27/bias) shape:[10], type:INT32 RO 40 bytes\n","  T#5(sequential_13/quantize_layer/AllValuesQuantize/FakeQuantWithMinMaxVars;quantize_layer/quantize_layer_min;quantize_layer/quantize_layer_max) shape_signature:[-1, 28, 28, 1], type:INT8\n","  T#6(sequential_13/quant_conv2d_13/Conv2D;sequential_13/quant_conv2d_13/LastValueQuant/FakeQuantWithMinMaxVarsPerChannel) shape:[32, 3, 3, 1], type:INT8 RO 288 bytes\n","  T#7(sequential_13/quant_conv2d_13/Relu;sequential_13/quant_conv2d_13/BiasAdd;sequential_13/quant_conv2d_13/Conv2D;conv2d_13/bias) shape_signature:[-1, 26, 26, 32], type:INT8\n","  T#8(sequential_13/quant_max_pooling2d_13/MaxPool) shape_signature:[-1, 8, 8, 32], type:INT8\n","  T#9(sequential_13/quant_flatten_13/Reshape) shape_signature:[-1, 2048], type:INT8\n","  T#10(sequential_13/quant_dense_26/MatMul;sequential_13/quant_dense_26/LastValueQuant/FakeQuantWithMinMaxVars) shape:[30, 2048], type:INT8 RO 61440 bytes\n","  T#11(sequential_13/quant_dense_26/MatMul;sequential_13/quant_dense_26/Relu;sequential_13/quant_dense_26/BiasAdd) shape_signature:[-1, 30], type:INT8\n","  T#12(sequential_13/quant_dense_27/MatMul;sequential_13/quant_dense_27/LastValueQuant/FakeQuantWithMinMaxVars) shape:[10, 30], type:INT8 RO 300 bytes\n","  T#13(sequential_13/quant_dense_27/MatMul;sequential_13/quant_dense_27/BiasAdd) shape_signature:[-1, 10], type:INT8\n","  T#14(sequential_13/quant_dense_27/Softmax) shape_signature:[-1, 10], type:INT8\n","  T#15(StatefulPartitionedCall:0) shape_signature:[-1, 10], type:FLOAT32\n","\n","---------------------------------------------------------------\n","Your TFLite model has ‘1’ signature_def(s).\n","\n","Signature#0 key: 'serving_default'\n","- Subgraph: Subgraph#0\n","- Inputs: \n","    'conv2d_13_input' : T#0\n","- Outputs: \n","    'quant_dense_27' : T#15\n","\n","---------------------------------------------------------------\n","              Model size:      66760 bytes\n","    Non-data buffer size:       4420 bytes (06.62 %)\n","  Total data buffer size:      62340 bytes (93.38 %)\n","    (Zero value buffers):          0 bytes (00.00 %)\n","\n","* Buffers of TFLite model are mostly used for constant tensors.\n","  And zero value buffers are buffers filled with zeros.\n","  Non-data buffers area are used to store operators, subgraphs and etc.\n","  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n","\n"]}]},{"cell_type":"code","source":["interpreter = tf.lite.Interpreter(model_content=tflite_model)\n","input_details = interpreter.get_input_details()\n","\n","interpreter.allocate_tensors()\n","output_details = interpreter.get_output_details()\n","\n","#Predictions from TFLite model\n","tfl_pred = []\n","tfl_pred_class = []\n","for i in range(len(x_test)):\n","    interpreter.set_tensor(input_details[0][\"index\"], x_test.astype('float32')[i:i+1,:])\n","    interpreter.invoke()\n","    result = interpreter.get_tensor(output_details[0][\"index\"])\n","    tfl_pred.append(result)\n","    tfl_pred_class.append(argmax(result))\n","\n","right_pred = [y_test_old[i] == tfl_pred_class[i] for i in range(len(y_test))]\n","acc = sum(right_pred)/len(right_pred)\n","print(acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYyKTL21oSbH","executionInfo":{"status":"ok","timestamp":1656654105214,"user_tz":240,"elapsed":2261,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"2bc6439f-86f9-4883-a023-ad03d5aa2982"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["0.933\n"]}]},{"cell_type":"markdown","source":["# **Conversion to C array**"],"metadata":{"id":"p6IRw0cym_IH"}},{"cell_type":"code","source":["# Function: Convert some hex value into an array for C programming\n","def hex_to_c_array(hex_data, var_name):\n","\n","  c_str = ''\n","\n","  # Create header guard\n","  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n","  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n","\n","  # Add array length at top of file\n","  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n","\n","  # Declare C variable\n","  c_str += 'unsigned char ' + var_name + '[] = {'\n","  hex_array = []\n","  for i, val in enumerate(hex_data) :\n","\n","    # Construct string from hex\n","    hex_str = format(val, '#04x')\n","\n","    # Add formatting so each line stays within 80 characters\n","    if (i + 1) < len(hex_data):\n","      hex_str += ','\n","    if (i + 1) % 12 == 0:\n","      hex_str += '\\n '\n","    hex_array.append(hex_str)\n","\n","  # Add closing brace\n","  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n","\n","  # Close out header guard\n","  c_str += '#endif //' + var_name.upper() + '_H'\n","\n","  return c_str"],"metadata":{"id":"rdyhA1gHni8R","executionInfo":{"status":"ok","timestamp":1656654105216,"user_tz":240,"elapsed":17,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Write TFLite model to a C source (or header) file\n","with open(\"CNN_pruned\" + '.h', 'w') as file:\n","  file.write(hex_to_c_array(tflite_model, \"CNN_pruned\"))"],"metadata":{"id":"sY4yr6OfnqAI","executionInfo":{"status":"ok","timestamp":1656654105217,"user_tz":240,"elapsed":16,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["# **Size Comparison**"],"metadata":{"id":"bnmiz7AGlZ-Y"}},{"cell_type":"code","source":["def get_gzipped_model_size(file):\n","  _, zipped_file = tempfile.mkstemp('.zip')\n","  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","    f.write(file)\n","\n","  return os.path.getsize(zipped_file)"],"metadata":{"id":"fM7eC4xAldem","executionInfo":{"status":"ok","timestamp":1656654105218,"user_tz":240,"elapsed":14,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n","print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n","print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size('CNN_pruned.tflite')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywNIeHiuledf","executionInfo":{"status":"ok","timestamp":1656654105384,"user_tz":240,"elapsed":178,"user":{"displayName":"Maxime Alos","userId":"14717728542823304691"}},"outputId":"68db30a6-a88a-445f-97f0-0c2fea1592c7"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of gzipped baseline Keras model: 232908.00 bytes\n","Size of gzipped pruned Keras model: 74528.00 bytes\n","Size of gzipped pruned TFlite model: 25416.00 bytes\n"]}]}]}