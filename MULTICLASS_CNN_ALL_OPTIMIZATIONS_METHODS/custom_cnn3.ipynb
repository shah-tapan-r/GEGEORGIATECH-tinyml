{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EDG9SjhsTgjE"},"outputs":[],"source":["#datasets from:\n","#https://www.kaggle.com/datasets/moltean/fruits"]},{"cell_type":"markdown","metadata":{"id":"uN6C5uhzTcav"},"source":["## Library load"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4256,"status":"ok","timestamp":1656454394796,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"uVa1ZItwTZak","outputId":"9c44f5d9-beeb-4522-ef15-5f879bccfcbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1656454394797,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"vlHPTBNBWiTD","outputId":"fb6696ee-543e-4465-9630-253aedd22c21"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Portofolio/fruit_quant_aware\n"]}],"source":["cd /content/drive/MyDrive/Portofolio/fruit_quant_aware"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1656454394798,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"6QH4Yz7dTZ28","outputId":"ddaffdcf-694c-4998-a3b3-21b6c8b7b023"},"outputs":[{"output_type":"stream","name":"stdout","text":["'Copy of custom_cnn3.ipynb'  'Copy of weight_clustering.ipynb'\t Validation\n","'Copy of mobilenet.ipynb'     Test\n","'Copy of pruning.ipynb'       Training\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2005,"status":"ok","timestamp":1656454396793,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"ksqxnIA5LlAj","outputId":"4a238e60-7555-4550-f08f-d213d9b7ec98"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.7/dist-packages (0.7.2)\n","Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.15.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (0.1.7)\n","Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization) (1.21.6)\n"]}],"source":[" !pip install  tensorflow-model-optimization\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8xDcJH5TZ8A"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import os\n","import glob\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","\n","from PIL import Image\n","from matplotlib import image as plt_image\n","import cv2\n","\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input \n","#mobilenet expects inputs in the range [-1 1] of float data type\n","\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n","from tensorflow.keras import Sequential \n","#https://keras.io/api/applications/mobilenet/ #mobilenet explanation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLROIApITZ9u"},"outputs":[],"source":["import tensorflow_model_optimization as tfmot\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"um-SAl-qTaA4"},"outputs":[],"source":["np.random.seed(42)# keras seed fixing \n","tf.random.set_seed(42)# tensorflow seed fixing"]},{"cell_type":"markdown","metadata":{"id":"lx3VD0bqZ8fX"},"source":["## Dataset Information"]},{"cell_type":"markdown","metadata":{"id":"f4COuq8MWdPa"},"source":["### train data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1656454397162,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"BVaZlcxhTaEV","outputId":"816c7b6c-278e-4bfe-bf9e-d084f74abf63"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of images in total 6231\n"]}],"source":["print(\"number of images in total\", len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\")))"]},{"cell_type":"markdown","source":["### val data"],"metadata":{"id":"NrhTJxd2Si9V"}},{"cell_type":"code","source":["print(\"number of images in total\", len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Validation/*/*\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XnN86ZQ5SnKU","executionInfo":{"status":"ok","timestamp":1656454397162,"user_tz":240,"elapsed":11,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"81bd99ac-f8d2-46b0-b173-60856366e75f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["number of images in total 3114\n"]}]},{"cell_type":"markdown","metadata":{"id":"XgrPoXgfWf3o"},"source":["### test data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656454397162,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"70ioTQa_Wf-k","outputId":"3731df63-9e7e-4105-b5ef-fb6d7ba4a527"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of images in total 3110\n"]}],"source":["print(\"number of images in total\", len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Test/*/*\")))"]},{"cell_type":"markdown","metadata":{"id":"HjagyiZlgr4i"},"source":["## Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656454397163,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"zRFWKaijh_05","outputId":"26003927-f277-4a82-e536-cf05cdc54dba"},"outputs":[{"output_type":"stream","name":"stdout","text":["(48, 48) (48, 48, 3)\n"]},{"output_type":"execute_result","data":{"text/plain":["0.001"]},"metadata":{},"execution_count":22}],"source":["class hyperparams:\n","  def __init__(self):\n","    self.dim2d = (48,48) #image dimensions we want downscale\n","    self.dim3d = (48,48,3) #128 is the minimum for mobilenet\n","    self.batch_size = 64\n","    self.no_epochs = 50#30\n","    self.lr = 1e-3\n","  \n","hparams =  hyperparams()\n","print(hparams.dim2d,hparams.dim3d)\n","hparams.lr"]},{"cell_type":"markdown","metadata":{"id":"UftMvxqmZ-_g"},"source":["##Data Augmentation"]},{"cell_type":"markdown","metadata":{"id":"YhIrBKioc7vB"},"source":["### augmentation and preprocess\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vxgBmT_T_aZ"},"outputs":[],"source":["def preproc(inp):#custom one without using tf functions\n","  return (inp*1.0/255)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"riRziuW9TaH_"},"outputs":[],"source":["train_datagen = ImageDataGenerator(#featurewise_center=True,\n","                             rotation_range=(0-30),\n","                             width_shift_range=0.2,\n","                             height_shift_range=0.2,\n","                             brightness_range=[0.5,1.5],\n","                             shear_range=0.2, \n","                             zoom_range=0.2,\n","                             channel_shift_range=0.2,\n","                             horizontal_flip=True, \n","                             #vertical_flip=True,\n","                             fill_mode='nearest',\n","                             preprocessing_function=preproc,\n","                             \n","                             dtype=float)\n","\n","val_datagen = ImageDataGenerator(\n","                                  dtype=float,\n","                                  preprocessing_function=preproc\n","                                  ) #no augmentation for test \n","\n","\n","test_datagen = ImageDataGenerator(\n","                                  dtype=float,\n","                                  preprocessing_function=preproc\n","                                  ) #no augmentation for test \n"]},{"cell_type":"markdown","metadata":{"id":"AdWIx7H4dAE0"},"source":["### post augmentation images and generator creation "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1358,"status":"ok","timestamp":1656454398513,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"H_G-rgV1gizy","outputId":"a0285ae8-0a5f-446a-e11c-036e6bd84542"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6231 images belonging to 24 classes.\n","Found 3114 images belonging to 24 classes.\n","Found 3110 images belonging to 24 classes.\n"]}],"source":["train_generator = train_datagen.flow_from_directory(\n","    \"Training\",\n","    target_size=hparams.dim2d,\n","    batch_size=hparams.batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    color_mode=\"rgb\",\n","    interpolation=\"bilinear\",\n","    ) # set as training data\n","\n","validation_generator = val_datagen.flow_from_directory(\n","    \"Validation\", # same directory as training data\n","    target_size=hparams.dim2d,\n","    batch_size=hparams.batch_size,\n","    class_mode='categorical',\n","    shuffle=False,\n","    color_mode=\"rgb\",\n","    interpolation=\"bilinear\",\n","    ) # set as validation data\n","\n","\n","test_generator = test_datagen.flow_from_directory(\n","    \"Test\", \n","    target_size=hparams.dim2d,\n","    batch_size=hparams.batch_size,\n","    class_mode='categorical',\n","    interpolation=\"bilinear\",\n","    color_mode=\"rgb\",\n","    ) # set as test data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29116,"status":"ok","timestamp":1656454427626,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"VTFQxnAqO25z","outputId":"513e9ddd-2e7d-4199-f208-900628806ca4"},"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 48, 48, 3)\n","float32\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.0, 1.0)"]},"metadata":{},"execution_count":26}],"source":[" img = next(train_generator)[0]\n"," print(img.shape)\n"," print(img.dtype)\n"," img.min(),img.max()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":284,"status":"ok","timestamp":1656454427897,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"92If51GmPH4G","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7db108c3-99ae-4f6d-d5d2-83a63b7985e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 48, 48, 3)\n","float32\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.0, 1.0)"]},"metadata":{},"execution_count":27}],"source":[" img = next(validation_generator)[0]\n"," print(img.shape)\n"," print(img.dtype)\n"," img.min(),img.max()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":31015,"status":"ok","timestamp":1656454458910,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"atWlkdNOPO0U","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9c2ba5d-63b6-430b-b84d-075bc39cfcae"},"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 48, 48, 3)\n","float32\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.0, 1.0)"]},"metadata":{},"execution_count":28}],"source":[" img = next(test_generator)[0]\n"," print(img.shape)\n"," print(img.dtype)\n"," img.min(),img.max()"]},{"cell_type":"markdown","metadata":{"id":"aXvkchFoWrDX"},"source":["## Model creation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1656461702446,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"Jd5f0pvUYu2A","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a7c1392-5839-4d5c-f2da-37448b2f727e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_6 (Conv2D)           (None, 46, 46, 16)        448       \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 46, 46, 16)       64        \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 44, 44, 16)        2320      \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 44, 44, 16)       64        \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 22, 22, 16)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_3 (Dropout)         (None, 22, 22, 16)        0         \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 20, 20, 32)        4640      \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 20, 20, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 18, 18, 32)        9248      \n","                                                                 \n"," batch_normalization_9 (Batc  (None, 18, 18, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 9, 9, 32)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_4 (Dropout)         (None, 9, 9, 32)          0         \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 7, 7, 64)          18496     \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 7, 7, 64)         256       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 5, 5, 64)          36928     \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 5, 5, 64)         256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_5 (Dropout)         (None, 2, 2, 64)          0         \n","                                                                 \n"," global_average_pooling2d_1   (None, 64)               0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_1 (Dense)             (None, 24)                1560      \n","                                                                 \n","=================================================================\n","Total params: 74,536\n","Trainable params: 74,088\n","Non-trainable params: 448\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n","\n","model = Sequential()\n","\n","model.add(Conv2D(16, (3, 3), activation='relu', input_shape=hparams.dim3d))\n","model.add(BatchNormalization())\n","model.add(Conv2D(16, (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(32, (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(32, (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(tf.keras.layers.GlobalAveragePooling2D())\n","model.add(Dense(24 , activation='softmax')) # 2 classes\n","\n","model.summary()"]},{"cell_type":"markdown","source":["**IMPORTANT**\n","\n","Each 32float param will be converted to an 8bit int one. Thus, for the QUANTIZED MODEL we will need roughly 71.3KB/0.06 MB of memory (73,041/(1024^2)) for the weights. The quantized tflite model will need more space though in order to store the architecture information and the quantization parameters that are needed."],"metadata":{"id":"Xjhc3k55wc42"}},{"cell_type":"markdown","metadata":{"id":"lrVIgCDnsS3-"},"source":["## Callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yeeyuy9hY4vj"},"outputs":[],"source":["# https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s_AkZVFOdvg3"},"outputs":[],"source":["'''\n","Adding Callbacks and EarlyStopping\n","Callbacks and Checkpoints help to keep an eye on model while training and stop the training\n","if the performance has reached an optimum.\n","'''\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","filepath = 'Callbacks/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5'\n","checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', \n","                             verbose = 1,\n","                             save_best_only = True,\n","                             mode = 'max',\n","                             save_freq = \"epoch\", #check and save at the end of the epoch   \n","                             save_weights_only=False,   #save model too   \n","                             )#best accuracy saved\n","\n","early_stop = EarlyStopping(monitor = 'val_loss',\n","                           patience = 7, #wait 7 epochs before you restore best weights and stop model trainng\n","                           mode=\"min\", \n","                           verbose = 1,\n","                           min_delta=0.01,\n","                           restore_best_weights=True)#go to the model that had the best accuracy before the early stopping before patience epochs\n","\n","#https://keras.io/api/callbacks/model_checkpoint/\n","#https://keras.io/api/callbacks/early_stopping/\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FE8mYSKMgRpP"},"source":["## Learning Rate and Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrdXrbf3j_Un"},"outputs":[],"source":["#https://towardsdatascience.com/learning-rate-schedule-in-practice-an-example-with-keras-and-tensorflow-2-0-2f48b2888a0c\n","#time decay\n","from tensorflow.keras.optimizers import Adam\n","\n","\n","\n","def lr_time_based_decay(epoch, lr):\n","    initial_learning_rate = hparams.lr \n","    epochs = hparams.no_epochs\n","    decay = initial_learning_rate / (epochs) *1000\n","\n","    return lr * 1 / (1 + decay * epoch)\n","\n","time_decay_learning_rate = tf.keras.callbacks.LearningRateScheduler (lr_time_based_decay, verbose=1) #CALLBACK \n","callbacks = [checkpoint, early_stop,time_decay_learning_rate]\n","optimizer = Adam(learning_rate=hparams.lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fITSG7Uj_gQ"},"outputs":[],"source":["# #https://towardsdatascience.com/learning-rate-schedule-in-practice-an-example-with-keras-and-tensorflow-2-0-2f48b2888a0c\n","# #step decay\n","# import math\n","# from tensorflow.keras.optimizers import Adam\n","\n","\n","\n","# def lr_step_decay(epoch, lr):\n","#     initial_learning_rate = hparams.lr #0.1\n","#     drop_rate = 0.5 #halfs the learning rate\n","#     epochs_drop = 10.0\n","#     return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n","\n","# step_decay_learning_rate = tensorflow.keras.callbacks.LearningRateScheduler (lr_step_decay, verbose=1) #CALLBACK \n","# callbacks = [model_checkpoint_callback,model_earlystop_callback,step_decay_learning_rate]\n","# optimizer = Adam(learning_rate=hparams.lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5JTIUSNtPTw"},"outputs":[],"source":["# #no policies\n","\n","# #optimizer \n","\n","# from tensorflow.keras.optimizers import Adam\n","# callbacks = [checkpoint, early_stop]\n","# optimizer = Adam(learning_rate=hparams.lr)"]},{"cell_type":"markdown","metadata":{"id":"DTG9gwi1eeT2"},"source":["## Model training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_pVmi9ZFVtW"},"outputs":[],"source":["model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = 'accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1388032,"status":"ok","timestamp":1656463093073,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"oDZ_RtTBeej9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4dd6849a-2d28-4440-cf6b-48c18807e293"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n","Epoch 1/50\n","97/97 [==============================] - ETA: 0s - loss: 2.3460 - accuracy: 0.2538\n","Epoch 1: val_accuracy improved from -inf to 0.05143, saving model to Callbacks/weights-improvement-01-0.05.hdf5\n","97/97 [==============================] - 55s 557ms/step - loss: 2.3460 - accuracy: 0.2538 - val_loss: 3.5117 - val_accuracy: 0.0514 - lr: 0.0010\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 0.0009803922034288739.\n","Epoch 2/50\n","97/97 [==============================] - ETA: 0s - loss: 1.4618 - accuracy: 0.4737\n","Epoch 2: val_accuracy improved from 0.05143 to 0.05436, saving model to Callbacks/weights-improvement-02-0.05.hdf5\n","97/97 [==============================] - 53s 549ms/step - loss: 1.4618 - accuracy: 0.4737 - val_loss: 4.9734 - val_accuracy: 0.0544 - lr: 9.8039e-04\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 0.0009426848219635967.\n","Epoch 3/50\n","97/97 [==============================] - ETA: 0s - loss: 1.2230 - accuracy: 0.5567\n","Epoch 3: val_accuracy improved from 0.05436 to 0.07357, saving model to Callbacks/weights-improvement-03-0.07.hdf5\n","97/97 [==============================] - 54s 553ms/step - loss: 1.2230 - accuracy: 0.5567 - val_loss: 5.2228 - val_accuracy: 0.0736 - lr: 9.4268e-04\n","\n","Epoch 4: LearningRateScheduler setting learning rate to 0.0008893253079633105.\n","Epoch 4/50\n","97/97 [==============================] - ETA: 0s - loss: 1.0405 - accuracy: 0.6144\n","Epoch 4: val_accuracy improved from 0.07357 to 0.18197, saving model to Callbacks/weights-improvement-04-0.18.hdf5\n","97/97 [==============================] - 53s 551ms/step - loss: 1.0405 - accuracy: 0.6144 - val_loss: 3.5765 - val_accuracy: 0.1820 - lr: 8.8933e-04\n","\n","Epoch 5: LearningRateScheduler setting learning rate to 0.0008234493348195596.\n","Epoch 5/50\n","97/97 [==============================] - ETA: 0s - loss: 0.9583 - accuracy: 0.6507\n","Epoch 5: val_accuracy improved from 0.18197 to 0.30990, saving model to Callbacks/weights-improvement-05-0.31.hdf5\n","97/97 [==============================] - 53s 554ms/step - loss: 0.9583 - accuracy: 0.6507 - val_loss: 2.4107 - val_accuracy: 0.3099 - lr: 8.2345e-04\n","\n","Epoch 6: LearningRateScheduler setting learning rate to 0.0007485903122208334.\n","Epoch 6/50\n","97/97 [==============================] - ETA: 0s - loss: 0.8507 - accuracy: 0.6887\n","Epoch 6: val_accuracy improved from 0.30990 to 0.41960, saving model to Callbacks/weights-improvement-06-0.42.hdf5\n","97/97 [==============================] - 53s 549ms/step - loss: 0.8507 - accuracy: 0.6887 - val_loss: 2.0224 - val_accuracy: 0.4196 - lr: 7.4859e-04\n","\n","Epoch 7: LearningRateScheduler setting learning rate to 0.0006683842262386211.\n","Epoch 7/50\n","97/97 [==============================] - ETA: 0s - loss: 0.7643 - accuracy: 0.7179\n","Epoch 7: val_accuracy improved from 0.41960 to 0.68034, saving model to Callbacks/weights-improvement-07-0.68.hdf5\n","97/97 [==============================] - 53s 551ms/step - loss: 0.7643 - accuracy: 0.7179 - val_loss: 1.1482 - val_accuracy: 0.6803 - lr: 6.6838e-04\n","\n","Epoch 8: LearningRateScheduler setting learning rate to 0.0005863019747234749.\n","Epoch 8/50\n","97/97 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.7475\n","Epoch 8: val_accuracy improved from 0.68034 to 0.77409, saving model to Callbacks/weights-improvement-08-0.77.hdf5\n","97/97 [==============================] - 53s 551ms/step - loss: 0.6898 - accuracy: 0.7475 - val_loss: 0.9648 - val_accuracy: 0.7741 - lr: 5.8630e-04\n","\n","Epoch 9: LearningRateScheduler setting learning rate to 0.0005054327253862446.\n","Epoch 9/50\n","97/97 [==============================] - ETA: 0s - loss: 0.6476 - accuracy: 0.7574\n","Epoch 9: val_accuracy did not improve from 0.77409\n","97/97 [==============================] - 54s 555ms/step - loss: 0.6476 - accuracy: 0.7574 - val_loss: 1.1937 - val_accuracy: 0.6657 - lr: 5.0543e-04\n","\n","Epoch 10: LearningRateScheduler setting learning rate to 0.000428332813020985.\n","Epoch 10/50\n","97/97 [==============================] - ETA: 0s - loss: 0.6097 - accuracy: 0.7733\n","Epoch 10: val_accuracy improved from 0.77409 to 0.79492, saving model to Callbacks/weights-improvement-10-0.79.hdf5\n","97/97 [==============================] - 53s 552ms/step - loss: 0.6097 - accuracy: 0.7733 - val_loss: 0.8580 - val_accuracy: 0.7949 - lr: 4.2833e-04\n","\n","Epoch 11: LearningRateScheduler setting learning rate to 0.00035694400139618665.\n","Epoch 11/50\n","97/97 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.7858\n","Epoch 11: val_accuracy improved from 0.79492 to 0.83594, saving model to Callbacks/weights-improvement-11-0.84.hdf5\n","97/97 [==============================] - 53s 551ms/step - loss: 0.5784 - accuracy: 0.7858 - val_loss: 0.8284 - val_accuracy: 0.8359 - lr: 3.5694e-04\n","\n","Epoch 12: LearningRateScheduler setting learning rate to 0.0002925770383969438.\n","Epoch 12/50\n","97/97 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.7993\n","Epoch 12: val_accuracy did not improve from 0.83594\n","97/97 [==============================] - 53s 550ms/step - loss: 0.5377 - accuracy: 0.7993 - val_loss: 0.8875 - val_accuracy: 0.7676 - lr: 2.9258e-04\n","\n","Epoch 13: LearningRateScheduler setting learning rate to 0.0002359492129706327.\n","Epoch 13/50\n","97/97 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.8088\n","Epoch 13: val_accuracy improved from 0.83594 to 0.83757, saving model to Callbacks/weights-improvement-13-0.84.hdf5\n","97/97 [==============================] - 53s 549ms/step - loss: 0.5199 - accuracy: 0.8088 - val_loss: 0.7657 - val_accuracy: 0.8376 - lr: 2.3595e-04\n","\n","Epoch 14: LearningRateScheduler setting learning rate to 0.00018726127491968254.\n","Epoch 14/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.8174\n","Epoch 14: val_accuracy did not improve from 0.83757\n","97/97 [==============================] - 53s 550ms/step - loss: 0.4996 - accuracy: 0.8174 - val_loss: 0.8410 - val_accuracy: 0.7819 - lr: 1.8726e-04\n","\n","Epoch 15: LearningRateScheduler setting learning rate to 0.00014629787301601027.\n","Epoch 15/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8299\n","Epoch 15: val_accuracy improved from 0.83757 to 0.84115, saving model to Callbacks/weights-improvement-15-0.84.hdf5\n","97/97 [==============================] - 54s 554ms/step - loss: 0.4674 - accuracy: 0.8299 - val_loss: 0.7382 - val_accuracy: 0.8411 - lr: 1.4630e-04\n","\n","Epoch 16: LearningRateScheduler setting learning rate to 0.00011253682224868008.\n","Epoch 16/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4631 - accuracy: 0.8224\n","Epoch 16: val_accuracy improved from 0.84115 to 0.84245, saving model to Callbacks/weights-improvement-16-0.84.hdf5\n","97/97 [==============================] - 53s 550ms/step - loss: 0.4631 - accuracy: 0.8224 - val_loss: 0.7748 - val_accuracy: 0.8424 - lr: 1.1254e-04\n","\n","Epoch 17: LearningRateScheduler setting learning rate to 8.525516794620533e-05.\n","Epoch 17/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.8260\n","Epoch 17: val_accuracy did not improve from 0.84245\n","97/97 [==============================] - 53s 544ms/step - loss: 0.4675 - accuracy: 0.8260 - val_loss: 0.7940 - val_accuracy: 0.8353 - lr: 8.5255e-05\n","\n","Epoch 18: LearningRateScheduler setting learning rate to 6.362325933226731e-05.\n","Epoch 18/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.8302\n","Epoch 18: val_accuracy improved from 0.84245 to 0.85254, saving model to Callbacks/weights-improvement-18-0.85.hdf5\n","97/97 [==============================] - 53s 552ms/step - loss: 0.4476 - accuracy: 0.8302 - val_loss: 0.7658 - val_accuracy: 0.8525 - lr: 6.3623e-05\n","\n","Epoch 19: LearningRateScheduler setting learning rate to 4.678180737434613e-05.\n","Epoch 19/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.8424\n","Epoch 19: val_accuracy improved from 0.85254 to 0.86133, saving model to Callbacks/weights-improvement-19-0.86.hdf5\n","97/97 [==============================] - 53s 551ms/step - loss: 0.4213 - accuracy: 0.8424 - val_loss: 0.7239 - val_accuracy: 0.8613 - lr: 4.6782e-05\n","\n","Epoch 20: LearningRateScheduler setting learning rate to 3.3899859640835046e-05.\n","Epoch 20/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.8364\n","Epoch 20: val_accuracy did not improve from 0.86133\n","97/97 [==============================] - 53s 551ms/step - loss: 0.4384 - accuracy: 0.8364 - val_loss: 0.7370 - val_accuracy: 0.8467 - lr: 3.3900e-05\n","\n","Epoch 21: LearningRateScheduler setting learning rate to 2.4214184252611763e-05.\n","Epoch 21/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.8429\n","Epoch 21: val_accuracy did not improve from 0.86133\n","97/97 [==============================] - 53s 551ms/step - loss: 0.4331 - accuracy: 0.8429 - val_loss: 0.7540 - val_accuracy: 0.8548 - lr: 2.4214e-05\n","\n","Epoch 22: LearningRateScheduler setting learning rate to 1.7052242980407498e-05.\n","Epoch 22/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.8453\n","Epoch 22: val_accuracy did not improve from 0.86133\n","97/97 [==============================] - 53s 549ms/step - loss: 0.4220 - accuracy: 0.8453 - val_loss: 0.7594 - val_accuracy: 0.8532 - lr: 1.7052e-05\n","\n","Epoch 23: LearningRateScheduler setting learning rate to 1.1841835758888112e-05.\n","Epoch 23/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.8359\n","Epoch 23: val_accuracy did not improve from 0.86133\n","97/97 [==============================] - 53s 550ms/step - loss: 0.4497 - accuracy: 0.8359 - val_loss: 0.7476 - val_accuracy: 0.8571 - lr: 1.1842e-05\n","\n","Epoch 24: LearningRateScheduler setting learning rate to 8.110846340981606e-06.\n","Epoch 24/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.8458\n","Epoch 24: val_accuracy did not improve from 0.86133\n","97/97 [==============================] - 53s 551ms/step - loss: 0.4264 - accuracy: 0.8458 - val_loss: 0.7542 - val_accuracy: 0.8564 - lr: 8.1108e-06\n","\n","Epoch 25: LearningRateScheduler setting learning rate to 5.480301665925623e-06.\n","Epoch 25/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.8322\n","Epoch 25: val_accuracy did not improve from 0.86133\n","97/97 [==============================] - 53s 550ms/step - loss: 0.4422 - accuracy: 0.8322 - val_loss: 0.7496 - val_accuracy: 0.8590 - lr: 5.4803e-06\n","\n","Epoch 26: LearningRateScheduler setting learning rate to 3.6535345013059364e-06.\n","Epoch 26/50\n","97/97 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8362\n","Epoch 26: val_accuracy did not improve from 0.86133\n","Restoring model weights from the end of the best epoch: 19.\n","97/97 [==============================] - 54s 554ms/step - loss: 0.4366 - accuracy: 0.8362 - val_loss: 0.7587 - val_accuracy: 0.8538 - lr: 3.6535e-06\n","Epoch 26: early stopping\n"]}],"source":["history = model.fit(\n","            train_generator,\n","            steps_per_epoch = train_generator.samples // hparams.batch_size,\n","            validation_data = validation_generator, \n","            validation_steps = validation_generator.samples // hparams.batch_size,\n","            epochs = hparams.no_epochs,\n","            callbacks=[callbacks])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15619,"status":"ok","timestamp":1656463108683,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"9FCJXLCqrk6O","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef33fcbf-bc7a-4a27-c884-35a2bcadf0bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["48/48 [==============================] - 15s 320ms/step - loss: 0.7239 - accuracy: 0.8613\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7239118218421936, 0.861328125]"]},"metadata":{},"execution_count":49}],"source":["model.evaluate(validation_generator, steps=validation_generator.samples // hparams.batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16103,"status":"ok","timestamp":1656463124777,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"vYQ-LaTppGVy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"927e9f65-2a3e-4ba6-eaf8-b83d3fb7bae8"},"outputs":[{"output_type":"stream","name":"stdout","text":["48/48 [==============================] - 15s 322ms/step - loss: 0.7140 - accuracy: 0.8646\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7139595150947571, 0.8645833134651184]"]},"metadata":{},"execution_count":50}],"source":["model.evaluate(test_generator, steps=test_generator.samples // hparams.batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2375,"status":"ok","timestamp":1656463127143,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"PrH3LGDhtZ1y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"763a7a59-8827-4a26-f2a7-522e78d3c6de"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/Portofolio/fruit_quant_aware/saved_models/assets\n"]}],"source":["model.save(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/saved_models/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVqCkYYMtZ8-","executionInfo":{"status":"ok","timestamp":1656463127601,"user_tz":240,"elapsed":460,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"colab":{"base_uri":"https://localhost:8080/","height":645},"outputId":"8716183e-323e-46b0-8739-654da753d23e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["#Evaluate the tensor size for the intermediate tensors (H*W*D)\n","\n","fig = plt.figure(dpi=100)\n","\n","ax = fig.add_axes([0,0,1,1])\n","\n","l_idx   = []\n","l_sizes = []\n","\n","for layer in model.layers[1:]:\n","  shape = layer.output_shape\n","  shape = np.delete(shape, 0)\n","  size  = np.prod(shape)\n","  l_idx   = np.append(l_idx, layer.name)\n","  l_sizes = np.append(l_sizes, size)\n","\n","ax.bar(l_idx, l_sizes)\n","plt.xticks(rotation='vertical')\n","plt.show()"]},{"cell_type":"markdown","source":["**IMPORTANT**\n","\n","We can have a rough estimation of the tensor arena by adding the size of the biGgest tensor multiplied by 2 and the size of the input and output. For our case the biggest tensor has roughly 35k parameters which means that when quantized it will need 35k *8bit size = 35 KB(35*1024B), 70KB when multiplied. As for the input it will be 48*48*3 parameters of 8bit each. Thus the input will need 7KB(7*1024). We will also need 1B for the output. In reality tensor arena will need more space cause it needs to accomodate more parameters.\n","\n","By our estimation it will need roughly 80KB"],"metadata":{"id":"fZwdqDpe4S5Q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNFfesYSeevh"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"k9vL3DpOfUbw"},"source":["## Quantization aware training model and finetune it\n"]},{"cell_type":"markdown","source":["#### Note that the resulting model is quantization aware but not quantized (e.g. the weights are float32 instead of int8). \n","\n","\n","**THE MODEL ITSELF ISN'T QUANTIZED.THE MODEL LEARNS PARAMETERS THAT ARE MORE ROBUST TO QUANTIZATION.**\n","\n","https://www.tensorflow.org/model_optimization/guide/quantization/training_example\n","\n","https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html"],"metadata":{"id":"c7UOCEeNSMWH"}},{"cell_type":"markdown","source":["#### quantize spacific type of layers"],"metadata":{"id":"6cckRvt5gaz8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKaVgCDdYz2I"},"outputs":[],"source":["# def apply_quantization_to_dense(layer):\n","#   if isinstance(layer, tf.keras.layers.Dense):\n","#     return tfmot.quantization.keras.quantize_annotate_layer(layer)\n","#   return layer\n","\n","#quant dense"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVS2sXvAaExX"},"outputs":[],"source":["# def apply_quantization_to_dense(layer):\n","#   if isinstance(layer, tf.keras.layers.Conv2D):\n","#     return tfmot.quantization.keras.quantize_annotate_layer(layer)\n","#   return layer\n","\n","#quant conv"]},{"cell_type":"code","source":["def apply_quantization_to_dense(layer):\n","  if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense):\n","    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n","  return layer\n","\n","\n","#quant conv and dense"],"metadata":{"id":"jwGyCSbRhDVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sa3CC-TVY0XR"},"outputs":[],"source":["annotated_model = tf.keras.models.clone_model(\n","    model,\n","    clone_function=apply_quantization_to_dense,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XelRiXTwY0aw"},"outputs":[],"source":["annotated_model.build((None, hparams.dim3d[0],hparams.dim3d[1],hparams.dim3d[2]))\n","\n","# Now that the Dense layers are annotated,\n","# `quantize_apply` actually makes the model quantization aware.\n","quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)"]},{"cell_type":"code","source":[""],"metadata":{"id":"VffFe7I3gkEJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### quantize everything"],"metadata":{"id":"diWxknm4gykg"}},{"cell_type":"code","source":["# import tensorflow_model_optimization as tfmot\n","\n","# quantize_model = tfmot.quantization.keras.quantize_model\n","\n","# # q_aware stands for for quantization aware.\n","# quant_aware_model = quantize_model(model)"],"metadata":{"id":"_FxCCXrtglCt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"4sC8mNiJglMP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sKL0XlZeZ8QM"},"outputs":[],"source":[""]},{"cell_type":"markdown","source":["#### finetune and perform quant aware training"],"metadata":{"id":"oazQSnBXhW17"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lx37C238Y0eO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656463130430,"user_tz":240,"elapsed":25,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"78f22e69-f6a0-4881-be67-45625f1042de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," quantize_layer (QuantizeLay  (None, 48, 48, 3)        3         \n"," er)                                                             \n","                                                                 \n"," quant_conv2d_6 (QuantizeWra  (None, 46, 46, 16)       483       \n"," pperV2)                                                         \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 46, 46, 16)       64        \n"," hNormalization)                                                 \n","                                                                 \n"," quant_conv2d_7 (QuantizeWra  (None, 44, 44, 16)       2355      \n"," pperV2)                                                         \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 44, 44, 16)       64        \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 22, 22, 16)       0         \n"," 2D)                                                             \n","                                                                 \n"," quant_dropout_3 (QuantizeWr  (None, 22, 22, 16)       1         \n"," apperV2)                                                        \n","                                                                 \n"," quant_conv2d_8 (QuantizeWra  (None, 20, 20, 32)       4707      \n"," pperV2)                                                         \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 20, 20, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," quant_conv2d_9 (QuantizeWra  (None, 18, 18, 32)       9315      \n"," pperV2)                                                         \n","                                                                 \n"," batch_normalization_9 (Batc  (None, 18, 18, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 9, 9, 32)         0         \n"," 2D)                                                             \n","                                                                 \n"," quant_dropout_4 (QuantizeWr  (None, 9, 9, 32)         1         \n"," apperV2)                                                        \n","                                                                 \n"," quant_conv2d_10 (QuantizeWr  (None, 7, 7, 64)         18627     \n"," apperV2)                                                        \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 7, 7, 64)         256       \n"," chNormalization)                                                \n","                                                                 \n"," quant_conv2d_11 (QuantizeWr  (None, 5, 5, 64)         37059     \n"," apperV2)                                                        \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 5, 5, 64)         256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_5 (Dropout)         (None, 2, 2, 64)          0         \n","                                                                 \n"," quant_global_average_poolin  (None, 64)               3         \n"," g2d_1 (QuantizeWrapperV2)                                       \n","                                                                 \n"," quant_dense_1 (QuantizeWrap  (None, 24)               1565      \n"," perV2)                                                          \n","                                                                 \n","=================================================================\n","Total params: 75,015\n","Trainable params: 74,088\n","Non-trainable params: 927\n","_________________________________________________________________\n"]}],"source":["quant_aware_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-u4crJxwY0gY"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QHIkwBD_bc7I"},"outputs":[],"source":["'''\n","Adding Callbacks and EarlyStopping\n","Callbacks and Checkpoints help to keep an eye on model while training and stop the training\n","if the performance has reached an optimum.\n","'''\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","filepath = 'Callbacks/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5'\n","checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', \n","                             verbose = 1,\n","                             save_best_only = True,\n","                             mode = 'max',\n","                             save_freq = \"epoch\", #check and save at the end of the epoch   \n","                             save_weights_only=False,   #save model too   \n","                             )#best accuracy saved\n","\n","early_stop = EarlyStopping(monitor = 'val_loss',\n","                           patience = 7, #wait 7 epochs before you restore best weights and stop model trainng\n","                           mode=\"min\", \n","                           verbose = 1,\n","                           min_delta=0.01,\n","                           restore_best_weights=True)#go to the model that had the best accuracy before the early stopping before patience epochs\n","\n","#https://keras.io/api/callbacks/model_checkpoint/\n","#https://keras.io/api/callbacks/early_stopping/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3oH6ejbbkFn"},"outputs":[],"source":["#https://towardsdatascience.com/learning-rate-schedule-in-practice-an-example-with-keras-and-tensorflow-2-0-2f48b2888a0c\n","#time decay\n","from tensorflow.keras.optimizers import Adam\n","\n","\n","\n","def lr_time_based_decay(epoch, lr):\n","    initial_learning_rate = hparams.lr /100\n","    epochs = hparams.no_epochs\n","    decay = initial_learning_rate / (epochs) *1000\n","\n","    return lr * 1 / (1 + decay * epoch)\n","\n","time_decay_learning_rate = tf.keras.callbacks.LearningRateScheduler (lr_time_based_decay, verbose=1) #CALLBACK \n","callbacks = [checkpoint, early_stop,time_decay_learning_rate]\n","optimizer = Adam(learning_rate=hparams.lr/100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V5a28qs4ZSo-"},"outputs":[],"source":["# `quantize_model` requires a recompile.\n","quant_aware_model.compile(optimizer=optimizer,\n","              loss=\"categorical_crossentropy\",\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270088,"status":"ok","timestamp":1656463400512,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"oao4h8fVsHG2","outputId":"8183574a-50e0-40ea-e94c-623fcc0d4af7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n","Epoch 1/5\n","97/97 [==============================] - ETA: 0s - loss: 0.7798 - accuracy: 0.7226\n","Epoch 1: val_accuracy improved from -inf to 0.74707, saving model to Callbacks/weights-improvement-01-0.75.hdf5\n","97/97 [==============================] - 55s 557ms/step - loss: 0.7798 - accuracy: 0.7226 - val_loss: 1.0060 - val_accuracy: 0.7471 - lr: 1.0000e-05\n","\n","Epoch 2: LearningRateScheduler setting learning rate to 9.998000147349282e-06.\n","Epoch 2/5\n","97/97 [==============================] - ETA: 0s - loss: 0.6498 - accuracy: 0.7738\n","Epoch 2: val_accuracy improved from 0.74707 to 0.83594, saving model to Callbacks/weights-improvement-02-0.84.hdf5\n","97/97 [==============================] - 53s 552ms/step - loss: 0.6498 - accuracy: 0.7738 - val_loss: 0.8223 - val_accuracy: 0.8359 - lr: 9.9980e-06\n","\n","Epoch 3: LearningRateScheduler setting learning rate to 9.994002167662488e-06.\n","Epoch 3/5\n","97/97 [==============================] - ETA: 0s - loss: 0.5988 - accuracy: 0.7873\n","Epoch 3: val_accuracy improved from 0.83594 to 0.83757, saving model to Callbacks/weights-improvement-03-0.84.hdf5\n","97/97 [==============================] - 54s 557ms/step - loss: 0.5988 - accuracy: 0.7873 - val_loss: 0.7892 - val_accuracy: 0.8376 - lr: 9.9940e-06\n","\n","Epoch 4: LearningRateScheduler setting learning rate to 9.988009733475177e-06.\n","Epoch 4/5\n","97/97 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.7984\n","Epoch 4: val_accuracy improved from 0.83757 to 0.84603, saving model to Callbacks/weights-improvement-04-0.85.hdf5\n","97/97 [==============================] - 53s 550ms/step - loss: 0.5481 - accuracy: 0.7984 - val_loss: 0.7528 - val_accuracy: 0.8460 - lr: 9.9880e-06\n","\n","Epoch 5: LearningRateScheduler setting learning rate to 9.980025858038849e-06.\n","Epoch 5/5\n","97/97 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.7981\n","Epoch 5: val_accuracy improved from 0.84603 to 0.85905, saving model to Callbacks/weights-improvement-05-0.86.hdf5\n","97/97 [==============================] - 54s 554ms/step - loss: 0.5358 - accuracy: 0.7981 - val_loss: 0.7392 - val_accuracy: 0.8590 - lr: 9.9800e-06\n"]}],"source":["history = quant_aware_model.fit(\n","            train_generator,\n","            steps_per_epoch = train_generator.samples // hparams.batch_size,\n","            validation_data = validation_generator, \n","            validation_steps = validation_generator.samples // hparams.batch_size,\n","            epochs = 5,\n","            callbacks=[callbacks]\n","            )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15538,"status":"ok","timestamp":1656463416036,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"B0QwmqqdsHJk","outputId":"1cb49c2a-c745-4fc0-dade-7c901ea7c5c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["48/48 [==============================] - 15s 320ms/step - loss: 0.7392 - accuracy: 0.8590\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7392217516899109, 0.8590494990348816]"]},"metadata":{},"execution_count":61}],"source":["quant_aware_model.evaluate(validation_generator, steps=validation_generator.samples // hparams.batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15792,"status":"ok","timestamp":1656463431818,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"aUebYthAsHLi","outputId":"9b513a0d-63ea-4f0f-a6b9-7d25dcebfb01"},"outputs":[{"output_type":"stream","name":"stdout","text":["48/48 [==============================] - 15s 322ms/step - loss: 0.7282 - accuracy: 0.8613\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7282493710517883, 0.861328125]"]},"metadata":{},"execution_count":62}],"source":["quant_aware_model.evaluate(test_generator, steps=test_generator.samples // hparams.batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4600,"status":"ok","timestamp":1656464115946,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"dsB9a_eLsHQN","outputId":"9df54ace-04fd-4b00-d779-645c1f2cea17"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as conv2d_6_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, dropout_3_layer_call_fn while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/Portofolio/fruit_quant_aware/quant_saved_models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/Portofolio/fruit_quant_aware/quant_saved_models/assets\n"]}],"source":["quant_aware_model.save(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/quant_saved_models/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dFWRTAJ8sHdY"},"outputs":[],"source":["temp = tf.keras.models.load_model('quant_saved_models')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15533,"status":"ok","timestamp":1656464151987,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"2AIoZP5m2xek","outputId":"2b978d2e-b583-4b8a-bd21-3ef6f1f79fc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["48/48 [==============================] - 15s 314ms/step - loss: 0.7392 - accuracy: 0.8590\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7392217516899109, 0.8590494990348816]"]},"metadata":{},"execution_count":68}],"source":["temp.evaluate(validation_generator, steps=validation_generator.samples // hparams.batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16036,"status":"ok","timestamp":1656464168013,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"iYn1_Dko2xiZ","outputId":"f8be42f8-0a52-46ed-ea1a-9b2bec1841a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["48/48 [==============================] - 15s 318ms/step - loss: 0.7283 - accuracy: 0.8607\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7283408045768738, 0.8606770634651184]"]},"metadata":{},"execution_count":69}],"source":["temp.evaluate(test_generator, steps=test_generator.samples // hparams.batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tckmW3dQ2xmL"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ChfLMSLZsHek"},"outputs":[],"source":[""]},{"cell_type":"markdown","source":["## SRAM MEMORY OF ARDUINO IS 256KB/0.25MB MODEL MUST FIT THERE"],"metadata":{"id":"cG7wRH4lJF--"}},{"cell_type":"markdown","source":["## Convert to TFLite"],"metadata":{"id":"9JeWvDr4svV5"}},{"cell_type":"code","source":["# labels = glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*\")\n","# labels = list(map(lambda x: x.split(\"/\")[-1], labels))\n","# labels[:2]"],"metadata":{"id":"dSSfuXP2-6lT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = list(train_generator.class_indices )\n","labels[:2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAE_HKgsB0QV","executionInfo":{"status":"ok","timestamp":1656465464792,"user_tz":240,"elapsed":5,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"b49166a7-c573-4978-adda-963da2c54298"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['apple_6', 'apple_braeburn_1']"]},"metadata":{},"execution_count":114}]},{"cell_type":"markdown","metadata":{"id":"Jl03f9MyzFQA"},"source":["## Quantization Aware Model Full-Integer Quantization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdoBtULg7PaI"},"outputs":[],"source":["def representative_data_gen():\n","\n","    imgs = tf.data.Dataset.from_tensor_slices(next(test_generator)[0]).batch(1)\n","    for i in imgs.take(64):#batch size\n","        i = tf.dtypes.cast(i, tf.float32)\n","        yield [i]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ax5XXgqO7PdY","outputId":"329156a6-58e8-4f1b-9895-fc6ab71acd63","executionInfo":{"status":"ok","timestamp":1656465927765,"user_tz":240,"elapsed":9552,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as conv2d_6_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, dropout_3_layer_call_fn while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmpwr0mq49h/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmpwr0mq49h/assets\n","/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["91304"]},"metadata":{},"execution_count":118}],"source":["converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n","converter.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","# converter.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","# converter.inference_input_type = tf.int8 #quant only the input\n","\n","tflite_model = converter.convert()\n","open(\"TFLite_Models/model.tflite\",\"wb\").write(tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXvxqt8m7Phw","executionInfo":{"status":"ok","timestamp":1656465932457,"user_tz":240,"elapsed":4705,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"29bacbcd-5a0c-4f10-f05e-fc73ff90f23c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Connecting to security.ubuntu.com (91.189.91.38)] [Connected to cloud.r-pro\r                                                                               \rHit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","\r0% [1 InRelease gpgv 242 kB] [4 InRelease 12.7 kB/88.7 kB 14%] [Connecting to s\r                                                                               \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [1 InRelease gpgv 242 kB] [4 InRelease 15.6 kB/88.7 kB 18%] [Connecting to s\r                                                                               \rHit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 242 kB] [4 InRelease 37.4 kB/88.7 kB 42%] [Connecting to s\r0% [1 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,298 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,065 kB]\n","Fetched 4,615 kB in 2s (2,682 kB/s)\n","Reading package lists... Done\n"]}],"source":["!apt-get update && apt-get -qq install xxd\n","!xxd -i TFLite_Models/model.tflite > TFLite_Models/model.h"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pHCql-bn7PkV","executionInfo":{"status":"ok","timestamp":1656465932457,"user_tz":240,"elapsed":3,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"04253800-f216-4ad0-ec62-83f82dc627fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Header file in MB: 0.5370559692382812\n","TFLite Model in MB: 0.08707427978515625\n","TFLite Model in KB: 89.1640625\n"]}],"source":["print(\"Header file in MB:\", os.path.getsize(\"TFLite_Models/model.h\") / float(2**20))\n","print(\"TFLite Model in MB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**20))\n","print(\"TFLite Model in KB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**10))\n","#print(len(tflite_model)/ float(2**20))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmKx13PX7Ppb"},"outputs":[],"source":["#accuracy evaluator\n","\n","# Initialize the TFLite interpreter\n","tfl_inter = tf.lite.Interpreter(model_content=tflite_model)\n","\n","# Allocate the tensors\n","tfl_inter.allocate_tensors()\n","\n","# Get input/output layer information\n","i_details = tfl_inter.get_input_details()[0]\n","o_details = tfl_inter.get_output_details()[0]\n","\n","def classify(i_data):\n","  \n","  input_data = i_data[np.newaxis, ...] #add batch dimension\n","  i_value_f32 = tf.dtypes.cast(input_data, tf.float32)\n","  \n","\n","  #leave input as it is\n","  i_value_s8 = i_value_f32\n","\n","  tfl_inter.set_tensor(i_details[\"index\"], i_value_s8)\n","  tfl_inter.invoke()\n","  o_pred = tfl_inter.get_tensor(o_details[\"index\"])[0]\n","\n","  # return (o_pred - o_zero_point) * o_scale\n","  return o_pred\n"]},{"cell_type":"code","source":["import PIL\n","from PIL import Image\n","print('Pillow Version:', PIL.__version__)\n","print(\"number of test images in total\", len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\")))"],"metadata":{"id":"eoFU9PeQFon_","executionInfo":{"status":"ok","timestamp":1656465932678,"user_tz":240,"elapsed":223,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"da41ca40-5134-4a6b-904b-b2bb2966f466"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pillow Version: 7.1.2\n","number of test images in total 6231\n"]}]},{"cell_type":"code","source":["num_correct_samples = 0\n","num_total_samples   = len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"))\n","\n","ind = 0\n","\n","for img_path in glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"):\n","  image = Image.open(img_path)\n","  image = image.resize(hparams.dim2d) #image resize\n","  image = np.array(image) #convert to numpy\n","  image = image/255.0 #standardize\n","\n","  pred = classify(image)\n","  label = (img_path.split(\"/\")[-2])#contains the true label\n","\n","  # print(labels[np.argmax(pred)],label)\n","  # break\n","  if labels[np.argmax(pred)]==label:\n","    num_correct_samples = num_correct_samples + 1\n","\n","  if ind%1000==0:\n","    print(f\"{ind+1} sample\")\n","  ind = ind + 1\n","  \n","\n","acc = num_correct_samples/num_total_samples\n","acc"],"metadata":{"id":"1qggxqkXHiB1","executionInfo":{"status":"ok","timestamp":1656466187007,"user_tz":240,"elapsed":254330,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4abbc301-c11d-4f64-801d-714252691122"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 sample\n","1001 sample\n","2001 sample\n","3001 sample\n","4001 sample\n","5001 sample\n","6001 sample\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8244262558176858"]},"metadata":{},"execution_count":123}]},{"cell_type":"markdown","metadata":{"id":"7H1wNq2pHGPD"},"source":["## Quantization Aware Model without quantization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8815,"status":"ok","timestamp":1656466195811,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"zPJu704v7PxG","outputId":"da7b1af8-b831-4669-d1ba-4d52977d70b3"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as conv2d_6_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, dropout_3_layer_call_fn while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmp5cebjz5l/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmp5cebjz5l/assets\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["617632"]},"metadata":{},"execution_count":124}],"source":["converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n","\n","tflite_model = converter.convert()\n","open(\"TFLite_Models/model.tflite\",\"wb\").write(tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4356,"status":"ok","timestamp":1656466200149,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"lhy22NFuHQ_V","outputId":"c943ce16-fc54-449c-9192-d9984cd00656"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Connecting to security.ubuntu.com (91.189.91.38)] [Connecting to cloud.r-pr\r                                                                               \rHit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","\r0% [1 InRelease gpgv 242 kB] [5 InRelease 11.3 kB/74.6 kB 15%] [Connecting to s\r                                                                               \rHit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 242 kB] [5 InRelease 17.1 kB/74.6 kB 23%] [Connecting to s\r                                                                               \rHit:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [1 InRelease gpgv 242 kB] [5 InRelease 17.1 kB/74.6 kB 23%] [Connecting to s\r                                                                               \rHit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Fetched 163 kB in 2s (97.7 kB/s)\n","Reading package lists... Done\n"]}],"source":["!apt-get update && apt-get -qq install xxd\n","!xxd -i TFLite_Models/model.tflite > TFLite_Models/model.h"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656466200149,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"FfwYnan27P00","outputId":"be1f76e8-2107-42c5-bf3c-7797b5019db1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Header file in MB: 3.632388114929199\n","TFLite Model in MB: 0.589019775390625\n","TFLite Model in KB: 603.15625\n"]}],"source":["print(\"Header file in MB:\", os.path.getsize(\"TFLite_Models/model.h\") / float(2**20))\n","print(\"TFLite Model in MB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**20))\n","print(\"TFLite Model in KB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**10))\n","#print(len(tflite_model)/ float(2**20))"]},{"cell_type":"code","source":["#accuracy evaluator\n","\n","# Initialize the TFLite interpreter\n","tfl_inter = tf.lite.Interpreter(model_content=tflite_model)\n","\n","# Allocate the tensors\n","tfl_inter.allocate_tensors()\n","\n","# Get input/output layer information\n","i_details = tfl_inter.get_input_details()[0]\n","o_details = tfl_inter.get_output_details()[0]\n","\n","\n","def classify(i_data):\n","  \n","  input_data = i_data[np.newaxis, ...] #add batch dimension\n","  i_value_f32 = tf.dtypes.cast(input_data, tf.float32)\n","  \n","\n","  #leave input as it is\n","  i_value_s8 = i_value_f32\n","\n","  tfl_inter.set_tensor(i_details[\"index\"], i_value_s8)\n","  tfl_inter.invoke()\n","  o_pred = tfl_inter.get_tensor(o_details[\"index\"])[0]\n","\n","  # return (o_pred - o_zero_point) * o_scale\n","  return o_pred\n"],"metadata":{"id":"E36L-ItkODTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import PIL\n","from PIL import Image\n","print('Pillow Version:', PIL.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5D-YUxXODYr","executionInfo":{"status":"ok","timestamp":1656466200371,"user_tz":240,"elapsed":228,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"992efc2e-268c-453c-d504-ee10f8a8294c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pillow Version: 7.1.2\n"]}]},{"cell_type":"code","source":["num_correct_samples = 0\n","num_total_samples   = len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"))\n","\n","ind = 0\n","\n","for img_path in glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"):\n","  image = Image.open(img_path)\n","  image = image.resize(hparams.dim2d) #image resize\n","  image = np.array(image) #convert to numpy\n","  image = image/255.0 #standardize\n","\n","  pred = classify(image)\n","  label = (img_path.split(\"/\")[-2])#contains the true label\n","\n","  # print(labels[np.argmax(pred)],label)\n","  # break\n","  if labels[np.argmax(pred)]==label:\n","    num_correct_samples = num_correct_samples + 1\n","\n","  if ind%1000==0:\n","    print(f\"{ind+1} sample\")\n","  ind = ind + 1\n","  \n","\n","acc = num_correct_samples/num_total_samples\n","acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OV8EFGe0ODa_","executionInfo":{"status":"ok","timestamp":1656466259389,"user_tz":240,"elapsed":59021,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"4b24d72e-d360-4c76-893a-e163832b0036"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 sample\n","1001 sample\n","2001 sample\n","3001 sample\n","4001 sample\n","5001 sample\n","6001 sample\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8425613866153105"]},"metadata":{},"execution_count":129}]},{"cell_type":"markdown","metadata":{"id":"KiQlOB7ut5pH"},"source":["\n","## Original model Full Integer Quantization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAknakG2wUxz"},"outputs":[],"source":["def representative_data_gen():\n","\n","    imgs = tf.data.Dataset.from_tensor_slices(next(test_generator)[0]).batch(1)\n","    for i in imgs.take(64):#batch size\n","        i = tf.dtypes.cast(i, tf.float32)\n","        yield [i]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5054,"status":"ok","timestamp":1656466264441,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"rKtEkkPAtun2","outputId":"a22b8ef7-a402-46d4-c892-ea4692ccaf4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmpt5w54fc2/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmpt5w54fc2/assets\n","/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["90440"]},"metadata":{},"execution_count":131}],"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","\n","tflite_model = converter.convert()\n","open(\"TFLite_Models/model.tflite\",\"wb\").write(tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4620,"status":"ok","timestamp":1656466269052,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"29fnpmAUtuq1","outputId":"650f0150-7b52-4023-82fa-1c268dbe3e0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Connecting to security.ubuntu.com (91.189.91.38)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","\r0% [1 InRelease gpgv 242 kB] [6 InRelease 11.3 kB/74.6 kB 15%] [Connecting to s\r                                                                               \rHit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 242 kB] [6 InRelease 14.2 kB/74.6 kB 19%] [Connecting to s\r                                                                               \rHit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Fetched 163 kB in 2s (96.6 kB/s)\n","Reading package lists... Done\n"]}],"source":["!apt-get update && apt-get -qq install xxd\n","!xxd -c 60 -i TFLite_Models/model.tflite > TFLite_Models/model.h"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1656466269052,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"},"user_tz":240},"id":"5Mr8tEq8uJhR","outputId":"cfd5736f-8f82-4a9e-8509-860a58122b32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Header file in MB: 0.5204753875732422\n","TFLite Model in MB: 0.08625030517578125\n","TFLite Model in KB: 88.3203125\n"]}],"source":["print(\"Header file in MB:\", os.path.getsize(\"TFLite_Models/model.h\") / float(2**20))\n","print(\"TFLite Model in MB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**20))\n","print(\"TFLite Model in KB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**10))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBw7sGT9uJlj"},"outputs":[],"source":["#accuracy evaluator\n","\n","# Initialize the TFLite interpreter\n","tfl_inter = tf.lite.Interpreter(model_content=tflite_model)\n","\n","# Allocate the tensors\n","tfl_inter.allocate_tensors()\n","\n","# Get input/output layer information\n","i_details = tfl_inter.get_input_details()[0]\n","o_details = tfl_inter.get_output_details()[0]\n","\n","\n","\n","def classify(i_data):\n","  \n","  input_data = i_data[np.newaxis, ...] #add batch dimension\n","  i_value_f32 = tf.dtypes.cast(input_data, tf.float32)\n","  \n","\n","  #leave input as it is\n","  i_value_s8 = i_value_f32\n","\n","  tfl_inter.set_tensor(i_details[\"index\"], i_value_s8)\n","  tfl_inter.invoke()\n","  o_pred = tfl_inter.get_tensor(o_details[\"index\"])[0]\n","\n","  # return (o_pred - o_zero_point) * o_scale\n","  return o_pred\n"]},{"cell_type":"code","source":["import PIL\n","from PIL import Image\n","print('Pillow Version:', PIL.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9VKDQ5vONh-","executionInfo":{"status":"ok","timestamp":1656466269291,"user_tz":240,"elapsed":5,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"62de5a73-8e28-40aa-ff05-53f9a075093a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pillow Version: 7.1.2\n"]}]},{"cell_type":"code","source":["num_correct_samples = 0\n","num_total_samples   = len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"))\n","\n","ind = 0\n","\n","for img_path in glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"):\n","  image = Image.open(img_path)\n","  image = image.resize(hparams.dim2d) #image resize\n","  image = np.array(image) #convert to numpy\n","  image = image/255.0 #standardize\n","\n","  pred = classify(image)\n","  label = (img_path.split(\"/\")[-2])#contains the true label\n","\n","  # print(labels[np.argmax(pred)],label)\n","  # break\n","  if labels[np.argmax(pred)]==label:\n","    num_correct_samples = num_correct_samples + 1\n","\n","  if ind%1000==0:\n","    print(f\"{ind+1} sample\")\n","  ind = ind + 1\n","  \n","\n","acc = num_correct_samples/num_total_samples\n","acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JC5GYB1RONnS","executionInfo":{"status":"ok","timestamp":1656466523119,"user_tz":240,"elapsed":253831,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"cb3e6794-90d0-449a-8e46-a34c7601713b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 sample\n","1001 sample\n","2001 sample\n","3001 sample\n","4001 sample\n","5001 sample\n","6001 sample\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8332530893917509"]},"metadata":{},"execution_count":136}]},{"cell_type":"markdown","source":["## Original model without quantization"],"metadata":{"id":"R9YYvxuWDMsg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NmeipMUxuJrH","executionInfo":{"status":"ok","timestamp":1656466528035,"user_tz":240,"elapsed":4927,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"54b4be38-e511-4dbf-8dc5-ec1017736de2"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmpy2z6qi_y/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmpy2z6qi_y/assets\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["304692"]},"metadata":{},"execution_count":137}],"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","\n","tflite_model = converter.convert()\n","open(\"TFLite_Models/model.tflite\",\"wb\").write(tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2RWpYa6tutF","executionInfo":{"status":"ok","timestamp":1656466532700,"user_tz":240,"elapsed":4675,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a0677044-abd0-470a-a320-60a420d614d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Connecting to security.ubuntu.com (91.189.91.38)] [Connected to cloud.r-pro\r                                                                               \rHit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Wa\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Connecting to security.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rHit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","\r0% [1 InRelease gpgv 242 kB] [7 InRelease 11.3 kB/74.6 kB 15%] [Connecting to s\r                                                                               \rHit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Fetched 163 kB in 2s (95.5 kB/s)\n","Reading package lists... Done\n"]}],"source":["!apt-get update && apt-get -qq install xxd\n","!xxd -c 60 -i TFLite_Models/model.tflite > TFLite_Models/model.h"]},{"cell_type":"code","source":["print(\"Header file in MB:\", os.path.getsize(\"TFLite_Models/model.h\") / float(2**20))\n","print(\"TFLite Model in MB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**20))\n","print(\"TFLite Model in KB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**10))"],"metadata":{"id":"A6V2q5wUD3cW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656466532701,"user_tz":240,"elapsed":22,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"f7add779-3948-4373-d08e-e2071395266f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Header file in MB: 1.7532472610473633\n","TFLite Model in MB: 0.2905769348144531\n","TFLite Model in KB: 297.55078125\n"]}]},{"cell_type":"code","source":["#accuracy evaluator\n","\n","# Initialize the TFLite interpreter\n","tfl_inter = tf.lite.Interpreter(model_content=tflite_model)\n","\n","# Allocate the tensors\n","tfl_inter.allocate_tensors()\n","\n","# Get input/output layer information\n","i_details = tfl_inter.get_input_details()[0]\n","o_details = tfl_inter.get_output_details()[0]\n","\n","\n","def classify(i_data):\n","  \n","  input_data = i_data[np.newaxis, ...] #add batch dimension\n","  i_value_f32 = tf.dtypes.cast(input_data, tf.float32)\n","  \n","  #leave input as it is\n","  i_value_s8 = i_value_f32\n","\n","  tfl_inter.set_tensor(i_details[\"index\"], i_value_s8)\n","  tfl_inter.invoke()\n","  o_pred = tfl_inter.get_tensor(o_details[\"index\"])[0]\n","\n","  # return (o_pred - o_zero_point) * o_scale\n","  return o_pred"],"metadata":{"id":"62kJwdGuOVB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import PIL\n","from PIL import Image\n","print('Pillow Version:', PIL.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bt3nsxk5OVFx","executionInfo":{"status":"ok","timestamp":1656466532931,"user_tz":240,"elapsed":16,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"afebce05-88b9-4c9b-e824-460521864a19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pillow Version: 7.1.2\n"]}]},{"cell_type":"code","source":["num_correct_samples = 0\n","num_total_samples   = len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"))\n","\n","ind = 0\n","\n","for img_path in glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"):\n","  image = Image.open(img_path)\n","  image = image.resize(hparams.dim2d) #image resize\n","  image = np.array(image) #convert to numpy\n","  image = image/255.0 #standardize\n","\n","  pred = classify(image)\n","  label = (img_path.split(\"/\")[-2])#contains the true label\n","\n","  # print(labels[np.argmax(pred)],label)\n","  # break\n","  if labels[np.argmax(pred)]==label:\n","    num_correct_samples = num_correct_samples + 1\n","\n","  if ind%1000==0:\n","    print(f\"{ind+1} sample\")\n","  ind = ind + 1\n","  \n","\n","acc = num_correct_samples/num_total_samples\n","acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKYz1L4qOVH3","executionInfo":{"status":"ok","timestamp":1656466574153,"user_tz":240,"elapsed":41235,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"00eb92ff-69e7-4be4-b42a-187a2304b238"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 sample\n","1001 sample\n","2001 sample\n","3001 sample\n","4001 sample\n","5001 sample\n","6001 sample\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8351789439897288"]},"metadata":{},"execution_count":142}]},{"cell_type":"markdown","source":["## Quantization Aware Model Full Integer Quantization with Input Quantization too"],"metadata":{"id":"0MfCJoZrMnzB"}},{"cell_type":"code","source":["def representative_data_gen():\n","\n","    imgs = tf.data.Dataset.from_tensor_slices(next(test_generator)[0]).batch(1)\n","    for i in imgs.take(64):#batch size\n","        i = tf.dtypes.cast(i, tf.float32)\n","        yield [i]"],"metadata":{"id":"vpp-6tnSgyDD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n","converter.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","converter.inference_input_type = tf.int8\n","\n","tflite_model = converter.convert()\n","open(\"TFLite_Models/model.tflite\",\"wb\").write(tflite_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sxIjVCwlNBT_","executionInfo":{"status":"ok","timestamp":1656466583360,"user_tz":240,"elapsed":9217,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"8d31675e-9ef6-454d-a03b-e20d339a4ca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as conv2d_6_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses, dropout_3_layer_call_fn while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmpga0xtvw7/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmpga0xtvw7/assets\n","/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["91008"]},"metadata":{},"execution_count":144}]},{"cell_type":"code","source":["!apt-get update && apt-get -qq install xxd\n","!xxd -c 60 -i TFLite_Models/model.tflite > TFLite_Models/model.h"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqd65R-PNBXh","executionInfo":{"status":"ok","timestamp":1656466588076,"user_tz":240,"elapsed":4728,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"5d9ac5a2-22a1-4416-c59d-a1085301dd80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Connecting to security.ubuntu.com (91.189.91.38)\r                                                                               \rHit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Connecting to security.ubuntu.com (91.189.91.38)\r                                                                               \rGet:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","\r0% [1 InRelease gpgv 15.9 kB] [7 InRelease 11.3 kB/74.6 kB 15%] [Connecting to \r                                                                               \rHit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Fetched 163 kB in 2s (98.1 kB/s)\n","Reading package lists... Done\n"]}]},{"cell_type":"code","source":["print(\"Header file in MB:\", os.path.getsize(\"TFLite_Models/model.h\") / float(2**20))\n","print(\"TFLite Model in MB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**20))\n","print(\"TFLite Model in KB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpduPtQpNBaq","executionInfo":{"status":"ok","timestamp":1656466588079,"user_tz":240,"elapsed":23,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"cd03211d-6af9-41b3-bd86-9265631aa5b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Header file in MB: 0.52374267578125\n","TFLite Model in MB: 0.0867919921875\n","TFLite Model in KB: 88.875\n"]}]},{"cell_type":"code","source":["#accuracy evaluator\n","\n","# Initialize the TFLite interpreter\n","tfl_inter = tf.lite.Interpreter(model_content=tflite_model)\n","\n","# Allocate the tensors\n","tfl_inter.allocate_tensors()\n","\n","# Get input/output layer information\n","i_details = tfl_inter.get_input_details()[0]\n","o_details = tfl_inter.get_output_details()[0]\n","\n","i_quant = i_details[\"quantization_parameters\"]\n","o_quant = o_details[\"quantization_parameters\"]\n","i_scale      = i_quant['scales'][0]\n","i_zero_point = i_quant['zero_points'][0]\n","\n","\n","\n","def classify(i_data):\n","  \n","  input_data = i_data[np.newaxis, ...] #add batch dimension\n","  i_value_f32 = tf.dtypes.cast(input_data, tf.float32)\n","  \n","  # Quantize (float -> 8-bit) the input (check if input layer is 8-bit, first)\n","  i_value_f32 = i_value_f32 / i_scale + i_zero_point\n","  i_value_s8 = tf.cast(i_value_f32, dtype=tf.int8)\n","\n","\n","  tfl_inter.set_tensor(i_details[\"index\"], i_value_s8)\n","  tfl_inter.invoke()\n","  o_pred = tfl_inter.get_tensor(o_details[\"index\"])[0]\n","\n","  return o_pred\n"],"metadata":{"id":"owLwgaG9NBhJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import PIL\n","from PIL import Image\n","print('Pillow Version:', PIL.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58dwi5hhNBiz","executionInfo":{"status":"ok","timestamp":1656466588081,"user_tz":240,"elapsed":22,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"856b8451-5710-47dc-d4dd-430f76a0e120"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pillow Version: 7.1.2\n"]}]},{"cell_type":"code","source":["num_correct_samples = 0\n","num_total_samples   = len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"))\n","\n","ind = 0\n","\n","for img_path in glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"):\n","  image = Image.open(img_path)\n","  image = image.resize(hparams.dim2d) #image resize\n","  image = np.array(image) #convert to numpy\n","  image = image/255.0 #standardize\n","\n","  pred = classify(image)\n","  label = (img_path.split(\"/\")[-2])#contains the true label\n","\n","  # print(labels[np.argmax(pred)],label)\n","  # break\n","  if labels[np.argmax(pred)]==label:\n","    num_correct_samples = num_correct_samples + 1\n","\n","  if ind%1000==0:\n","    print(f\"{ind+1} sample\")\n","  ind = ind + 1\n","  \n","\n","acc = num_correct_samples/num_total_samples\n","acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lAgA0iKaNBkK","executionInfo":{"status":"ok","timestamp":1656466844484,"user_tz":240,"elapsed":256421,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"3a7f1053-6ae3-4994-fd8b-9d809b945c5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 sample\n","1001 sample\n","2001 sample\n","3001 sample\n","4001 sample\n","5001 sample\n","6001 sample\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8194511314395763"]},"metadata":{},"execution_count":149}]},{"cell_type":"markdown","source":["## Original Model Full Integer Quantization with Input Quantization too"],"metadata":{"id":"-1XEE0UlZl2C"}},{"cell_type":"code","source":["def representative_data_gen():\n","\n","    imgs = tf.data.Dataset.from_tensor_slices(next(test_generator)[0]).batch(1)\n","    for i in imgs.take(64):#batch size\n","        i = tf.dtypes.cast(i, tf.float32)\n","        yield [i]"],"metadata":{"id":"65iz-nC4NBle"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.representative_dataset = tf.lite.RepresentativeDataset(representative_data_gen)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","converter.inference_input_type = tf.int8\n","# converter.inference_output_type = tf.int8\n","\n","tflite_model = converter.convert()\n","open(\"TFLite_Models/model.tflite\",\"wb\").write(tflite_model)"],"metadata":{"id":"ciK8_2WIgyEn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656466850020,"user_tz":240,"elapsed":5538,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"347f57f0-e791-4f54-bba3-58dd36aec41c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmp5cgw7coi/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmp5cgw7coi/assets\n","/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n","  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n","WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["90256"]},"metadata":{},"execution_count":151}]},{"cell_type":"code","source":["!apt-get update && apt-get -qq install xxd\n","!xxd -c 60 -i TFLite_Models/model.tflite > TFLite_Models/model.h"],"metadata":{"id":"Ll3tseppgyFr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656466854716,"user_tz":240,"elapsed":4699,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"dcc2cd56-7ad1-48e8-83e9-55a004977afa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [Waiting for headers] [Con\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [2 InRelease 14.2 kB/88.7 \r0% [1 InRelease gpgv 15.9 kB] [Connecting to archive.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Connecting to archive.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Connecting to archive.ubuntu.com (91.189.91.38)]\r0% [1 InRelease gpgv 15.9 kB] [Connecting to archive.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Connecting to archive.ubuntu.com (91.189.91.38)]\r                                                                               \rHit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Fetched 163 kB in 2s (94.6 kB/s)\n","Reading package lists... Done\n"]}]},{"cell_type":"code","source":["print(\"Header file in MB:\", os.path.getsize(\"TFLite_Models/model.h\") / float(2**20))\n","print(\"TFLite Model in MB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**20))\n","print(\"TFLite Model in KB:\", os.path.getsize(\"TFLite_Models/model.tflite\") / float(2**10))\n","#print(len(tflite_model)/ float(2**20))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dn6SJeXOauT9","executionInfo":{"status":"ok","timestamp":1656466854717,"user_tz":240,"elapsed":6,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"1fdd5023-c6c5-4596-b743-4e5a6084b17d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Header file in MB: 0.5194168090820312\n","TFLite Model in MB: 0.0860748291015625\n","TFLite Model in KB: 88.140625\n"]}]},{"cell_type":"code","source":["#accuracy evaluator\n","\n","# Initialize the TFLite interpreter\n","tfl_inter = tf.lite.Interpreter(model_content=tflite_model)\n","\n","# Allocate the tensors\n","tfl_inter.allocate_tensors()\n","\n","# Get input/output layer information\n","i_details = tfl_inter.get_input_details()[0]\n","o_details = tfl_inter.get_output_details()[0]\n","\n","i_quant = i_details[\"quantization_parameters\"]\n","o_quant = o_details[\"quantization_parameters\"]\n","i_scale      = i_quant['scales'][0]\n","i_zero_point = i_quant['zero_points'][0]\n","\n","\n","\n","def classify(i_data):\n","  \n","  input_data = i_data[np.newaxis, ...] #add batch dimension\n","  i_value_f32 = tf.dtypes.cast(input_data, tf.float32)\n","  \n","  # Quantize (float -> 8-bit) the input (check if input layer is 8-bit, first)\n","  i_value_f32 = i_value_f32 / i_scale + i_zero_point\n","  i_value_s8 = tf.cast(i_value_f32, dtype=tf.int8)\n","\n","\n","\n","  tfl_inter.set_tensor(i_details[\"index\"], i_value_s8)\n","  tfl_inter.invoke()\n","  o_pred = tfl_inter.get_tensor(o_details[\"index\"])[0]\n","\n","  return o_pred\n"],"metadata":{"id":"LEv10B94auXr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import PIL\n","from PIL import Image\n","print('Pillow Version:', PIL.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVyxHn61auZi","executionInfo":{"status":"ok","timestamp":1656466855075,"user_tz":240,"elapsed":3,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"16b5728e-cf7b-4d47-df3f-2578e60af94a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pillow Version: 7.1.2\n","number of test images in total 200\n"]}]},{"cell_type":"code","source":["num_correct_samples = 0\n","num_total_samples   = len(glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"))\n","\n","ind = 0\n","\n","for img_path in glob.glob(\"/content/drive/MyDrive/Portofolio/fruit_quant_aware/Training/*/*\"):\n","  image = Image.open(img_path)\n","  image = image.resize(hparams.dim2d) #image resize\n","  image = np.array(image) #convert to numpy\n","  image = image/255.0 #standardize\n","\n","  pred = classify(image)\n","  label = (img_path.split(\"/\")[-2])#contains the true label\n","\n","  # print(labels[np.argmax(pred)],label)\n","  # break\n","  if labels[np.argmax(pred)]==label:\n","    num_correct_samples = num_correct_samples + 1\n","\n","  if ind%1000==0:\n","    print(f\"{ind+1} sample\")\n","  ind = ind + 1\n","  \n","\n","acc = num_correct_samples/num_total_samples\n","acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDB0UYL3audz","executionInfo":{"status":"ok","timestamp":1656467111372,"user_tz":240,"elapsed":256298,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"4f5ece0a-81a7-487c-b133-14057b73ed2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 sample\n","1001 sample\n","2001 sample\n","3001 sample\n","4001 sample\n","5001 sample\n","6001 sample\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8478574867597496"]},"metadata":{},"execution_count":156}]},{"cell_type":"markdown","source":["## create an image as example"],"metadata":{"id":"OmxBPoLnjX2p"}},{"cell_type":"code","source":["import sys\n","import numpy\n","np.set_printoptions(threshold=sys.maxsize)\n","\n","for img_path in glob.glob(\"/content/drive/MyDrive/Portofolio/fire_detection_quant_aware/combined_test/*/*\"):\n","  image = Image.open(img_path)\n","  image = image.resize(hparams.dim2d) #image resize\n","  image = np.array(image) #convert to numpy\n","  \n","  label = (img_path.split(\"/\")[-2])#contains the true label\n","  print(label)\n","  break\n","\n","image.flatten()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qfnt7VqXjZYx","executionInfo":{"status":"ok","timestamp":1655954145303,"user_tz":240,"elapsed":4,"user":{"displayName":"Venetis Pallikaras","userId":"14147789031826417236"}},"outputId":"ddccc1e8-15b5-478a-e6c2-37e7a88b4d9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fire\n"]},{"output_type":"execute_result","data":{"text/plain":["array([ 18,  12,  12,  20,  14,  14,  20,  14,  14,  25,  16,  15,  26,\n","        16,  15,  23,  13,  12,  17,   7,   6,  18,   8,   7,  20,  10,\n","         9,  21,  11,  10,  21,   8,   8,  25,  10,  10,  24,  11,   6,\n","        23,   9,   7,  23,   9,   9,  22,   8,   8,  23,   9,   9,  20,\n","         7,   7,  14,   2,   4,  15,   3,   5,  16,   4,   5,  15,   3,\n","         3,  15,   4,   3,  19,   3,   6,  21,   3,   8,  25,   5,   7,\n","        36,   4,   8,  35,   9,   8,  41,  15,   6,  43,  18,   9,  31,\n","         8,   3,  35,   7,   2,  46,  15,   9,  49,  15,   6,  45,  17,\n","         9,  36,  15,  14,  34,  11,   8,  33,  13,   4,  29,  10,   4,\n","        20,   4,   1,  14,   2,   1,  15,   3,   2,  27,  11,   5,  32,\n","        11,   7,  35,  13,   6,  28,   9,   3,  19,   6,   5,  14,   3,\n","         4,  19,  13,  13,  24,  18,  18,  17,  11,  10,  27,  17,  15,\n","        28,  18,  16,  22,  12,  10,  19,   9,   6,  20,  10,   7,  22,\n","        12,   9,  21,  11,   9,  22,  10,   8,  26,  11,   9,  29,  13,\n","         7,  23,   8,   5,  23,   7,   7,  23,   7,   7,  25,   9,   8,\n","        23,   8,   8,  19,   5,   6,  20,   6,   7,  19,   5,   5,  19,\n","         6,   4,  20,   7,   5,  19,   6,   5,  20,   7,   6,  25,   7,\n","         5,  32,   7,   5,  37,  11,   8,  41,  12,   3,  41,  12,   4,\n","        35,   8,   6,  44,  14,  14,  46,  15,  13,  51,  17,   8,  42,\n","        14,   5,  36,  14,  12,  40,  16,   9,  41,  15,   3,  35,  12,\n","         6,  25,   8,   5,  17,   3,   2,  25,  10,   7,  33,  15,   8,\n","        30,   8,   4,  41,  17,   9,  35,  14,   7,  23,   9,   7,  13,\n","         1,   1,  23,  17,  17,  25,  19,  19,  19,  13,  13,  31,  23,\n","        16,  30,  21,  15,  27,  17,  11,  29,  16,  11,  30,  17,  12,\n","        26,  13,   8,  21,  12,   6,  22,  11,   6,  28,  13,   8,  32,\n","        14,   6,  28,  10,   5,  27,   7,   5,  26,   7,   5,  27,   8,\n","         5,  26,   7,   5,  23,   6,   6,  23,   6,   6,  26,  10,   9,\n","        33,  17,  13,  30,  14,  10,  22,   9,   4,  26,  11,   6,  44,\n","        20,  14,  41,  18,  11,  37,  13,   7,  52,  20,  13,  61,  26,\n","        18,  42,  11,   5,  43,  13,  13,  38,   8,   8,  50,  16,   6,\n","        42,  13,   5,  27,   9,   7,  30,  11,   5,  37,  11,   2,  34,\n","         8,   5,  28,   9,   6,  18,   1,   2,  28,  11,   7,  37,  17,\n","         7,  39,  14,   6,  45,  19,   9,  36,  14,   4,  28,  12,   7,\n","        21,   5,   4,  21,  15,  15,  26,  21,  21,  18,  13,  12,  24,\n","        16,   9,  31,  22,  14,  29,  19,  11,  27,  12,   8,  28,  13,\n","         9,  23,  10,   5,  18,  10,   4,  27,  15,   9,  36,  20,  13,\n","        35,  16,   6,  36,  17,  10,  27,   9,   4,  28,   9,   5,  32,\n","        14,   9,  26,   8,   4,  26,   8,   6,  25,   7,   4,  28,  10,\n","         8,  31,  13,   9,  31,  14,   9,  30,  13,   7,  44,  21,  15,\n","        51,  19,  14,  35,  11,   4,  34,   9,   3,  74,  37,  26,  96,\n","        56,  41,  51,  16,   1,  40,  10,   5,  34,   6,   4,  43,  11,\n","         3,  37,  10,   2,  17,   4,   4,  13,   3,   2,  31,  12,  10,\n","        31,   8,   8,  28,   6,   4,  25,   5,   6,  32,  12,   7,  36,\n","        14,   3,  40,  14,   4,  45,  16,   5,  38,  13,   3,  31,  12,\n","         6,  27,   9,   6,  19,  17,  15,  20,  18,  17,  18,  17,  15,\n","        22,  17,  12,  31,  21,  12,  40,  24,  12,  36,  16,  13,  23,\n","         9,  11,  23,   8,   5,  26,  14,   6,  39,  19,  10,  48,  21,\n","        10,  45,  20,   6,  39,  20,  10,  30,  13,   7,  39,  15,   8,\n","        35,  14,   9,  32,  13,   9,  31,  14,  10,  31,  12,   8,  28,\n","        10,   8,  24,   8,   9,  30,  17,  14,  31,  19,  13,  30,  11,\n","         9,  24,   9,   6,  44,  14,   9,  77,  31,  12,  83,  28,   9,\n","        61,  18,  10,  84,  32,  11,  61,  19,   7,  33,   8,   8,  33,\n","        13,   6,  32,  15,   6,  31,  12,   7,  17,   2,   2,  26,   9,\n","        12,  21,   5,   6,  20,   2,   1,  33,   9,   4,  45,  21,  12,\n","        34,  10,   6,  40,  13,   2,  48,  17,   6,  46,  16,  10,  39,\n","        11,   8,  34,  11,   7,  13,  12,  10,  16,  15,  13,  15,  13,\n","        11,  26,  19,  15,  41,  28,  20,  47,  29,  17,  33,  15,  12,\n","        22,   7,   8,  39,  16,   9,  61,  30,  10,  58,  30,  13,  51,\n","        23,  11,  52,  20,   8,  48,  22,  15,  36,  12,   8,  56,  23,\n","        16,  54,  23,  18,  40,  15,  12,  29,  14,  10,  34,  18,  15,\n","        30,  17,  15,  19,  10,  12,  16,   6,   5,  10,   3,   2,  24,\n","         8,  14,  55,  27,  20,  88,  31,  12,  95,  26,   3,  88,  33,\n","        10,  58,  22,  18,  94,  32,  20,  85,  29,  10,  59,  20,   8,\n","        49,  19,   6,  44,  20,   6,  44,  17,   7,  32,   8,   4,  35,\n","        11,   9,  24,   4,   3,  20,   1,   1,  35,  10,   5,  49,  23,\n","        11,  40,  15,   5,  46,  16,  11,  44,  12,   6,  43,  13,   6,\n","        39,  11,   8,  33,  10,   5,  17,  16,  14,  22,  21,  19,  14,\n","        13,  11,  29,  19,  15,  45,  29,  21,  51,  31,  20,  27,  10,\n","         8,  29,  12,  10,  61,  32,  20,  68,  30,   8,  61,  30,  10,\n","        54,  27,  10,  51,  20,   9,  39,  14,   8,  28,   9,   5,  24,\n","        10,   5,  20,   9,   5,  13,   4,   3,  14,   3,   3,  16,   4,\n","         4,  13,   2,   2,  14,   6,   6,  37,  22,  20,  26,  14,  13,\n","        12,   1,   7,  26,   6,   3,  83,  34,  17, 111,  42,  13,  99,\n","        41,  13,  54,  17,  13,  86,  26,  15,  91,  28,   3,  79,  28,\n","         8,  55,  17,   5,  43,  15,   4,  42,  15,   6,  39,  13,   5,\n","        39,  13,  10,  27,   5,   3,  27,   5,   5,  42,  13,  10,  46,\n","        17,   6,  46,  18,  10,  51,  19,  13,  46,  13,   7,  37,   7,\n","         2,  35,   8,   4,  31,   8,   4,  22,  20,  19,  28,  27,  26,\n","        22,  20,  19,  23,  13,  12,  52,  32,  26,  55,  32,  20,  25,\n","         7,   6,  35,  15,  11,  50,  21,   9,  51,  20,   6,  55,  24,\n","         5,  54,  25,   4,  46,  20,   6,  34,  12,   4,  24,   8,   4,\n","        25,   8,  10,  20,   5,   6,  23,   7,   7,  27,   9,   6,  29,\n","        11,   9,  34,  17,  12,  33,  15,   9,  51,  25,  21,  41,  21,\n","        16,   7,   1,   1,   7,   5,   7,  47,  23,  17,  76,  27,   9,\n","        96,  39,  18,  75,  35,  28,  85,  36,  17,  97,  33,   6,  77,\n","        23,   6,  57,  20,   9,  36,  12,   5,  30,   7,   3,  31,  10,\n","         5,  30,   8,   7,  28,   6,   5,  29,   4,   5,  43,  13,  10,\n","        39,   9,   6,  41,  11,   9,  53,  19,   8,  52,  18,   7,  41,\n","        11,   5,  38,  10,   6,  32,   9,   4,  21,  19,  18,  32,  29,\n","        36,  25,  24,  27,  20,  15,  19,  52,  28,  24,  61,  35,  21,\n","        40,  21,  19,  60,  31,  19,  38,  17,   9,  47,  23,   9,  69,\n","        33,  11,  69,  34,  14,  65,  32,  15,  68,  31,  13,  37,  14,\n","         6,  48,  18,  13,  77,  31,   7,  98,  41,   7, 100,  39,  12,\n","        98,  37,  11, 103,  44,  13,  94,  36,  16,  98,  41,  24,  56,\n","        28,  19,   4,   1,   1,  10,   3,   6,  83,  37,  12,  89,  38,\n","        14,  84,  40,  23,  74,  46,  42,  50,  20,  11,  88,  30,  13,\n","        78,  28,  11,  39,  10,   4,  26,   6,   6,  29,   4,   4,  35,\n","        11,   9,  36,  11,   6,  31,   6,   2,  32,   8,   4,  38,  13,\n","         8,  27,   7,   6,  42,  16,  11,  59,  22,   7,  51,  16,   4,\n","        42,  12,   4,  36,   9,   4,  37,  11,   6,  20,  19,  19,  33,\n","        30,  39,  32,  30,  34,  24,  14,  15,  33,  15,  11,  29,  17,\n","        13,  48,  29,  21, 107,  65,  43,  75,  36,  21,  58,  27,  12,\n","        74,  35,   8,  71,  33,   6,  66,  28,  11,  60,  29,  15,  43,\n","        17,  10,  55,  18,  11, 104,  42,  11, 110,  43,   6, 110,  45,\n","         7, 109,  45,   7, 113,  46,   9, 119,  48,  12, 130,  63,  18,\n","        79,  42,  32,   2,   0,   1,  11,   3,   7,  91,  39,  12, 116,\n","        45,  12, 105,  42,  14,  35,   9,   6,  14,   4,   2,  57,  18,\n","         8,  53,  19,   8,  19,   2,   2,  12,   1,   5,  24,   4,   5,\n","        31,  10,   6,  42,  15,  10,  38,  11,   6,  37,  14,  11,  31,\n","         8,   5,  29,   8,   6,  55,  25,  15,  63,  26,   8,  53,  18,\n","         9,  38,   7,   5,  35,   6,   6,  37,  11,  10,  18,  16,  19,\n","        34,  30,  43,  31,  28,  35,  60,  48,  46,  92,  75,  61,  53,\n","        41,  38,  42,  18,  13, 149,  92,  58, 145,  81,  38, 113,  59,\n","        23, 124,  65,  20, 116,  61,  24,  78,  35,  17,  38,  15,  12,\n","        44,  19,  13,  55,  18,   7, 116,  45,   8, 116,  44,   7, 115,\n","        45,   5, 116,  47,   7, 119,  48,   8, 127,  48,  12, 137,  62,\n","        17,  81,  39,  28,   2,   0,   1,   9,   2,   6,  92,  43,  14,\n","       121,  56,  12, 103,  47,  12,  28,  13,  12,  10,   4,   3,  58,\n","        24,  14,  44,  16,   8,  18,   7,   9,  12,   4,   6,  24,   7,\n","         5,  33,  15,  11,  46,  17,  14,  37,  10,   7,  26,   6,   6,\n","        25,   5,   5,  34,  11,   6,  60,  25,   9,  64,  26,   6,  55,\n","        21,  10,  38,   7,   5,  35,   7,   6,  32,   7,   6,  28,  26,\n","        30,  43,  38,  52,  37,  32,  41,  80,  69,  66, 140, 118,  93,\n","        77,  57,  49,  50,  21,  24, 164,  97,  52, 203, 123,  51, 189,\n","       111,  35, 172,  91,  26, 147,  71,  25,  85,  39,  22,  30,  14,\n","        15,  48,  25,  20,  60,  30,  14, 121,  51,   9, 123,  51,  13,\n","       120,  47,  10, 122,  48,  11, 125,  49,   8, 157,  84,  56, 192,\n","       125, 106,  94,  55,  43,   1,   0,   1,  11,   2,   6,  96,  43,\n","        16, 128,  53,  15, 111,  48,  16,  33,  11,  15,  17,   5,   4,\n","        69,  27,  15,  44,  12,   7,  19,   5,   6,  20,   6,   5,  28,\n","         9,   6,  26,   9,   5,  46,  16,  12,  38,   9,   7,  21,   3,\n","         3,  21,   3,   4,  49,  22,  13,  64,  26,   5,  61,  25,   3,\n","        55,  22,   8,  45,  14,   4,  42,  15,   7,  30,   7,   4,  53,\n","        47,  52,  53,  45,  57,  33,  28,  35,  41,  35,  31, 150, 127,\n","        99,  67,  47,  46,  56,  23,  26, 155,  86,  36, 189, 108,  31,\n","       192, 112,  33, 188, 109,  33, 167,  86,  22, 101,  50,  32,  24,\n","        10,   7,  27,  10,   8,  49,  26,  17, 120,  56,  17, 132,  56,\n","        13, 126,  52,  10, 131,  52,   6, 154,  74,  42, 226, 201, 196,\n","       217, 174, 166,  98,  60,  46,   3,   1,   7,  15,   3,   6, 108,\n","        51,  16, 130,  56,  18, 120,  57,  23,  39,  12,  15,  18,  12,\n","         8,  78,  30,  13,  33,   6,   5,  22,   6,   9,  15,   2,   4,\n","        21,   4,   3,  30,   7,   4,  41,  13,   6,  32,   7,   2,  23,\n","         7,   7,  21,   4,   3,  56,  24,  11,  68,  28,   9,  61,  26,\n","         9,  58,  21,   8,  58,  22,   4,  46,  17,   6,  30,   7,   5,\n","        32,  26,  31,  47,  40,  52,  32,  26,  31,  85,  72,  61, 147,\n","       122, 101,  56,  34,  32,  80,  49,  41, 139,  72,  36, 190, 117,\n","        33, 196, 122,  41, 189, 112,  34, 180, 100,  28, 106,  58,  35,\n","        18,   7,   5,  27,  12,  10,  39,  19,  16, 109,  48,  15, 139,\n","        60,  14, 132,  53,   9, 143,  54,  14, 207, 143, 124, 241, 238,\n","       238, 217, 169, 138,  99,  62,  41,   6,   0,   8,  14,   2,   6,\n","       127,  68,  32, 158,  80,  34, 160, 106,  73,  36,  21,  20,  30,\n","        11,   9, 103,  44,  30,  43,  20,  12,  21,   9,   5,  41,  19,\n","        14,  41,  10,   5,  31,   8,   7,  38,  13,  10,  30,   6,   2,\n","        24,   6,   4,  32,  12,   9,  50,  20,  12,  56,  21,  12,  65,\n","        23,  11,  62,  20,   7,  56,  20,   7,  47,  17,  10,  32,   8,\n","         5,  64,  57,  63,  50,  42,  55,  41,  34,  38, 121, 106,  98,\n","        70,  53,  47,  60,  44,  39,  90,  62,  49, 148,  89,  44, 201,\n","       137,  53, 198, 131,  49, 195, 121,  38, 188, 109,  29,  88,  46,\n","        20,  12,   2,   5,  21,   8,   7,  22,   7,  10,  97,  42,  17,\n","       148,  63,  16, 142,  56,  10, 189, 110,  76, 226, 159, 135, 232,\n","       155, 129, 219, 136, 108, 117,  72,  59,   9,   0,   7,  14,   5,\n","         7, 119,  62,  34, 155,  77,  35, 141,  82,  58,  35,  17,  12,\n","        68,  36,  34, 150,  97,  77,  71,  28,  14,  32,   4,   2, 100,\n","        62,  56, 110,  61,  47,  38,   9,   6,  44,  14,  12,  32,   6,\n","         2,  25,   6,   2,  32,  10,   6,  53,  21,  12,  59,  23,  12,\n","        62,  22,   9,  64,  24,   9,  51,  14,   7,  44,  14,  11,  37,\n","        12,   8,  45,  40,  44,  49,  42,  54,  41,  35,  40,  39,  29,\n","        33,  46,  38,  42,  65,  57,  52,  89,  61,  48, 182, 127,  61,\n","       230, 171,  91, 219, 156,  74, 206, 134,  49, 197, 117,  33, 110,\n","        63,  26,  16,   5,  12,  13,   4,   4,  12,   0,   4,  92,  40,\n","        19, 166,  72,  26, 190,  92,  47, 222, 147, 111, 232, 173, 140,\n","       237, 159, 132, 226, 165, 145,  96,  54,  39,  12,   2,   8,  16,\n","         6,   9,  93,  41,  23, 144,  67,  35, 117,  52,  37,  49,  17,\n","        13, 107,  68,  65, 188, 149, 124,  96,  38,  25,  30,   9,   8,\n","       102,  82,  74, 173, 132, 108,  70,  27,  17,  46,  12,   7,  33,\n","         4,   1,  28,   6,   4,  39,  15,   9,  65,  27,   9,  72,  32,\n","        11,  53,  20,   6,  56,  20,   7,  53,  15,   9,  43,  12,   9,\n","        37,  11,   6,  17,  17,  17,  44,  43,  52,  41,  40,  46,  38,\n","        39,  41,  62,  60,  61,  60,  55,  56,  91,  65,  52, 217, 165,\n","        99, 255, 213, 120, 248, 197, 102, 221, 158,  67, 204, 128,  40,\n","       142,  77,  28,  29,   8,  13,   9,   3,   7,  11,   4,   5,  63,\n","        26,  18, 131,  56,  40, 149,  72,  55, 133,  71,  50, 144,  85,\n","        63, 144,  73,  58, 125,  73,  62,  51,  19,  17,  22,  10,  12,\n","        12,   2,   6,  89,  45,  33, 188,  95,  42, 162,  95,  75,  76,\n","        37,  34, 137,  99,  91, 205, 171, 151,  98,  38,  23,  40,  13,\n","        10,  99,  73,  64, 187, 136, 109, 106,  55,  39,  48,  16,  13,\n","        35,   5,   6,  36,   8,  11,  46,  17,   9,  76,  35,   8,  70,\n","        30,  10,  46,  15,   8,  42,  12,   5,  51,  18,   6,  54,  22,\n","         3,  49,  17,   6,  16,  16,  18,  46,  44,  56,  40,  38,  47,\n","        48,  46,  49,  60,  56,  55,  67,  61,  58,  56,  42,  31, 147,\n","       115,  74, 171, 137,  84, 130,  93,  57, 119,  73,  40, 159, 104,\n","        74, 186, 138, 112,  68,  44,  30,  15,   3,   5,  26,  14,  17,\n","        27,  12,  19,  19,   2,  10,  16,   4,   7,  18,   5,   9,  24,\n","         8,   9,  35,  14,   9,  33,  14,  16,  36,  15,  23,  30,  11,\n","        15,   9,   3,   5,  69,  34,  20, 201, 116,  56, 187, 122,  89,\n","        92,  50,  40,  96,  55,  45, 132,  78,  56,  87,  23,   6,  43,\n","        14,   6,  79,  36,  20, 131,  58,  36,  64,  19,  13,  46,  11,\n","        10,  37,   7,   7,  33,   5,   4,  57,  23,  10,  78,  37,  11,\n","        61,  23,   7,  42,  13,   7,  33,  10,   4,  40,  15,   5,  57,\n","        20,   7,  58,  18,  10,  40,  39,  44,  51,  49,  63,  44,  41,\n","        52,  71,  67,  72,  65,  58,  55,  65,  57,  48,  29,  20,  19,\n","        33,  17,  13,  41,  21,  13,  42,  17,  11,  37,   8,   5,  58,\n","        27,  23, 103,  68,  55,  82,  46,  31,  38,  15,  13,  42,  13,\n","        10,  33,  10,  10,  21,   8,  10,  26,   6,  11,  29,   6,  11,\n","        34,  12,  15,  34,  22,  15,  37,  21,  18,  40,  20,  23,  35,\n","        18,  22,  17,   8,  10,  49,  26,  27, 177, 130,  94, 225, 178,\n","       146, 105,  67,  55,  48,  11,   5, 129,  58,  39,  95,  43,  23,\n","        53,  22,  13,  69,  34,  24, 121,  65,  47,  52,  20,  16,  45,\n","        14,  12,  37,  10,   6,  42,  13,   5,  82,  39,  18,  78,  36,\n","        12,  60,  24,   9,  38,  10,   6,  35,  13,   9,  40,  14,   7,\n","        51,  18,   9,  45,  11,   9,  38,  37,  42,  51,  48,  63,  44,\n","        42,  55,  69,  64,  70,  90,  83,  80,  77,  69,  58,  32,  24,\n","        11,  31,  22,  15,  27,  14,   9,  37,  21,   9,  39,  20,   9,\n","        34,  16,   4,  47,  23,   9,  69,  30,  25,  41,  18,  13,  29,\n","        13,  13,  30,  13,  10,  23,  11,   5,  26,   7,   7,  24,   8,\n","         7,  25,  14,  12,  27,  19,  17,  30,  22,  20,  35,  24,  25,\n","        37,  25,  27,  20,   6,   8,  33,  14,  24,  83,  66,  62, 126,\n","        91,  80,  64,  32,  29,  44,  17,  15,  99,  38,  29,  64,  33,\n","        23,  34,  11,   9,  22,   7,  13,  29,  12,   9,  23,   5,   4,\n","        29,  11,   8,  24,   7,   3,  41,  16,   7,  74,  34,  15,  70,\n","        31,  11,  60,  26,  12,  37,  12,   8,  32,   6,   6,  38,   8,\n","         5,  40,  13,   7,  34,  13,  12,  35,  32,  31,  48,  46,  58,\n","        44,  44,  57,  66,  63,  63,  43,  39,  34,  60,  56,  47,  44,\n","        40,  27,  31,  25,  17,  19,  11,   8,  18,  10,   6,  25,  11,\n","         5,  29,  10,   4,  48,  29,  15,  64,  42,  25,  61,  34,  27,\n","        30,   7,   7,  32,  15,  14,  42,  16,  19,  35,  13,  13,  29,\n","        10,  10,  31,  16,  13,  34,  20,  16,  30,  19,  18,  33,  21,\n","        24,  39,  24,  27,  23,   7,  10,  22,   5,   7,  22,   2,   4,\n","        20,   0,   2,  17,   0,   2,  16,   1,   6,  15,   0,   5,  12,\n","         0,   4,  14,   1,   6,  16,   2,   7,  10,   0,   1,   9,   0,\n","         0,   5,   2,   3,   3,   2,   3,  10,   4,   3,  21,   7,   6,\n","        39,  16,  11,  34,   8,   3,  25,   9,   5,  28,  10,  10,  31,\n","         7,   7,  34,   9,   7,  36,  13,  12,  58,  55,  54,  44,  42,\n","        54,  42,  44,  56,  41,  42,  38,  62,  59,  47,  94,  88,  72,\n","        32,  37,  23,  21,  20,  10,  21,  16,   8,  17,  11,   3,  23,\n","        11,   3,  35,  17,   7,  64,  40,  26,  88,  61,  43,  56,  28,\n","        22,  21,   4,   9,  34,  10,   8,  54,  19,  10,  68,  23,  10,\n","        65,  23,   9,  71,  31,  14,  80,  43,  26,  61,  37,  32,  33,\n","        18,  21,  34,  21,  23,  26,  12,  15,  14,   2,   3,  11,   2,\n","         2,  12,   3,   2,  12,   3,   4,   8,   1,   4,   7,   1,   4,\n","        10,   1,   3,  37,  13,  21,  43,  15,  25,  11,   3,   5,   2,\n","         3,   3,   6,   1,   7,   6,   2,   8,   5,   4,   7,   7,   2,\n","         3,   9,   0,   1,   8,   0,   1,   5,   3,   3,   8,   2,   3,\n","        17,   3,   6,  28,   9,  10,  33,  12,  11,  82,  79,  77,  49,\n","        47,  59,  46,  47,  61,  37,  40,  42,  77,  73,  65,  90,  80,\n","        63,  33,  29,  12,  48,  35,  17,  58,  37,  21,  56,  33,  17,\n","        63,  34,  18,  74,  39,  21,  89,  49,  27,  98,  57,  31,  81,\n","        33,  15, 133,  64,  45, 176,  97,  71, 198, 122,  81, 206, 131,\n","        79, 205, 132,  77, 214, 153,  93, 230, 201, 142, 179, 163, 131,\n","        31,  19,  10,  33,  22,  25,  26,  15,  17,  12,   3,   5,  10,\n","         3,   5,  11,   3,   5,  10,   3,   5,   8,   2,   4,   8,   2,\n","         4,   8,   2,   3,  41,  15,  24,  51,  20,  31,  14,   6,   6,\n","         6,   2,   1,   7,   1,   2,   9,   3,   8,   8,   3,   8,   7,\n","         3,   4,   6,   1,   4,   7,   1,   6,   8,   3,   3,   8,   4,\n","         3,  12,   1,   1,  29,   8,   7,  41,  15,  14,  28,  27,  27,\n","        53,  51,  65,  53,  54,  68,  31,  35,  42,  37,  33,  27,  59,\n","        47,  34,  59,  42,  25, 130, 105,  82, 164, 132, 106, 153, 113,\n","        92, 143,  95,  74, 141,  91,  68, 146,  96,  68, 131,  77,  46,\n","       136,  69,  35, 233, 134,  71, 254, 154,  85, 255, 173,  98, 254,\n","       194, 119, 255, 201, 127, 253, 212, 141, 255, 247, 186, 195, 185,\n","       154,  30,  19,  13,  28,  17,  18,  17,   7,   8,  13,   2,   5,\n","        13,   1,   6,  11,   1,   5,  11,   1,   5,  11,   0,   4,  11,\n","         0,   4,  10,   2,   4,  33,  10,  18,  40,  13,  23,  25,  10,\n","        10,  58,  28,  20,  24,  10,   5,  11,   3,   2,   9,   1,   4,\n","        13,   6,   5,  25,  14,  14,  15,   1,   7,  23,   8,  10,  27,\n","        13,   9,  25,   8,   3,  41,  14,  10,  39,  12,   8,  36,  40,\n","        45,  47,  46,  63,  55,  53,  68,  49,  51,  55,  27,  26,  16,\n","        50,  42,  30,  69,  52,  36, 146, 130, 108, 171, 155, 127, 145,\n","       110,  90, 132,  83,  65, 137,  92,  69, 146,  97,  73, 153,  91,\n","        62, 174,  99,  58, 245, 160,  84, 254, 177,  93, 254, 192, 114,\n","       253, 218, 143, 253, 239, 180, 254, 247, 218, 255, 255, 240, 197,\n","       191, 173,  41,  18,  13,  31,  16,  14,  14,   3,   2,  21,  10,\n","        12,  15,   2,   7,  10,   1,   4,   9,   2,   4,  10,   1,   4,\n","        10,   1,   4,  11,   1,   4,  29,   8,  15,  39,  14,  23,  47,\n","        21,  17, 110,  36,  18,  51,  17,  12,  18,   7,   5,   5,   3,\n","         6,  31,  13,   8,  52,  24,  13,  16,   1,   8,  26,  10,  14,\n","        36,  11,   6,  33,   5,   3,  39,  11,   8,  37,  13,  11,  31,\n","        32,  35,  39,  41,  57,  51,  54,  72,  41,  43,  50,  23,  21,\n","        17,  26,  17,  14,  76,  59,  45, 168, 152, 126, 171, 154, 128,\n","       150, 116,  94, 156, 115,  91, 146, 101,  76, 152,  99,  71, 158,\n","        92,  60, 184, 107,  64, 249, 173, 103, 248, 189, 109, 253, 209,\n","       131, 254, 231, 159, 250, 251, 207, 248, 255, 252, 254, 253, 251,\n","       181, 148, 137,  47,  21,  13,  41,  24,  23,  16,   4,   4,  36,\n","        24,  27,  21,   8,  12,  10,   1,   3,   9,   1,   4,  10,   1,\n","         4,  10,   1,   4,  10,   1,   3,  27,   9,  13,  40,  19,  25,\n","        54,  22,  19, 112,  29,  15,  56,  22,  15,  24,  12,  10,   8,\n","         3,   8,  55,  20,   8,  66,  27,  10,  13,   1,   7,  29,  10,\n","        10,  41,  12,   6,  33,   6,   3,  34,   6,   4,  35,  11,   9,\n","        19,  20,  18,  41,  45,  60,  46,  56,  74,  26,  30,  30,  21,\n","        19,  12,  23,  14,  12,  81,  64,  51, 167, 152, 121, 170, 151,\n","       127, 161, 131, 105, 158, 126,  97, 160, 114,  87, 156,  98,  66,\n","       164,  93,  56, 188, 108,  62, 247, 179, 107, 250, 191, 111, 252,\n","       201, 123, 249, 214, 133, 246, 237, 171, 251, 252, 220, 229, 196,\n","       178, 160,  91,  75,  42,  27,  17,  40,  22,  22,  20,   5,   6,\n","        22,  10,  12,  16,   5,   8,  11,   2,   5,   9,   2,   4,  10,\n","         1,   4,  10,   1,   4,   9,   1,   2,  28,  14,  14,  43,  25,\n","        27,  35,  10,  10,  89,  23,  16,  42,  17,  12,  27,  11,  13,\n","        12,   3,  10,  63,  26,  14,  77,  35,  20,   9,   1,   5,  39,\n","        18,  14,  52,  17,   8,  34,   7,   4,  36,   8,   5,  29,   5,\n","         4,  20,  21,  19,  35,  40,  51,  37,  47,  60,  24,  28,  23,\n","        26,  24,  13,  35,  25,  19,  72,  55,  43, 158, 144, 112, 169,\n","       149, 126, 167, 135, 109, 162, 128,  98, 167, 119,  88, 171, 111,\n","        78, 171, 101,  64, 185, 104,  58, 233, 158,  89, 242, 180,  98,\n","       234, 176, 102, 224, 167, 105, 224, 174, 115, 193, 145, 109, 168,\n","       115,  94, 116,  74,  58,  47,  17,  27,  35,  14,  15,  38,  21,\n","        22,  33,  14,  17,  37,  21,  23,  18,   7,  10,  10,   1,   4,\n","         9,   1,   4,   9,   1,   4,   6,   0,   2,  35,  23,  21,  61,\n","        43,  40,  36,  23,  22,  53,  14,  10,  32,  13,  11,  22,   6,\n","         8,  12,   5,   9,  42,  12,   6,  57,  17,   9,  11,   2,   5,\n","        34,  14,  10,  50,  15,   9,  34,   7,   5,  37,  10,   8,  30,\n","         7,   5,  16,  20,  17,  23,  27,  26,  31,  35,  36,  26,  27,\n","        24,  17,  13,   8,  18,   8,   3,  60,  46,  36, 125, 109,  85,\n","       131, 109,  86, 149, 114,  92, 150, 102,  74, 157,  98,  64, 164,\n","        99,  64, 168,  96,  61, 194, 117,  70, 232, 174, 109, 252, 233,\n","       147, 245, 234, 167, 199, 163, 122, 136,  76,  43, 108,  55,  33,\n","       152, 100,  62, 166, 123,  88,  51,  23,  26,  37,  15,  15,  48,\n","        28,  27,  42,  15,  16,  37,  17,  15,  20,   9,  10,  11,   0,\n","         4,   7,   1,   3,   7,   1,   3,   4,   0,   2,  27,  19,  14,\n","        70,  54,  43,  35,  23,  22,  59,  19,  11,  43,  12,   9,  18,\n","         3,   7,  12,   5,   7,  36,  10,   5,  54,  13,   9,  13,   1,\n","         2,  28,  10,   9,  40,  12,  10,  28,   6,   4,  30,   8,   5,\n","        28,   7,   3,  13,  18,  12,  20,  25,  22,  28,  32,  32,  24,\n","        26,  19,  22,  17,  11,  15,   6,   3,  44,  34,  28, 137, 120,\n","        96, 122,  98,  74, 131, 102,  83, 152, 109,  83, 152,  99,  68,\n","       116,  63,  40, 101,  44,  26, 139,  80,  56, 130,  68,  36, 210,\n","       152,  97, 171, 106,  67,  90,  41,  21,  81,  39,  10, 114,  52,\n","        26, 173,  94,  42, 189, 115,  64,  50,  24,  20,  33,  14,  12,\n","        29,  13,  12,  82,  60,  56,  66,  54,  48,  24,  22,  20,   6,\n","         0,   3,   7,   1,   3,   7,   1,   3,   4,   0,   2,  22,  14,\n","        11,  63,  47,  37,  39,  21,  19,  71,  19,  11,  44,  13,   9,\n","        24,   8,  13,  18,   2,  10,  42,  17,   9,  53,  21,  12,  14,\n","         1,   3,  30,  14,  12,  37,  14,   9,  25,   5,   2,  28,   8,\n","         5,  25,   6,   3,  13,  19,  10,  12,  17,  11,  18,  23,  19,\n","        30,  33,  22,  24,  19,  13,  16,   5,   5,  30,  23,  19, 116,\n","        98,  74, 131, 104,  75, 110,  85,  66, 101,  74,  58,  59,  34,\n","        21,  30,   9,   5,  29,   8,   9,  29,  11,  12,  42,  15,  14,\n","        99,  42,  15, 110,  39,  13,  89,  33,  16,  83,  35,  13,  97,\n","        40,  13, 120,  57,  25, 125,  68,  39,  44,  22,  14,  41,  25,\n","        19,  26,  13,  13, 112,  93,  83,  45,  33,  27,  16,  13,  11,\n","         7,   1,   4,   7,   1,   3,   7,   1,   3,   4,   1,   2,  25,\n","        17,  12,  62,  45,  35,  38,  23,  19,  68,  23,   9,  50,  18,\n","        10,  26,  13,  12,  22,   8,   9,  23,   8,   2,  34,  18,   8,\n","        22,   8,  10,  29,  12,  10,  32,  14,   8,  30,  12,   8,  30,\n","        12,   8,  24,   7,   4,   7,  13,   4,  12,  17,  10,  17,  22,\n","        16,  22,  25,  14,  15,  11,   6,  15,   6,   6,  21,  12,   8,\n","        70,  54,  34,  88,  64,  41,  60,  40,  26,  25,  12,   5,  18,\n","         9,   7,  20,   5,   3,  19,   5,   5,  23,  10,   8,  33,  11,\n","         8,  37,  11,   4,  42,  18,  12,  54,  18,  11,  55,  17,  12,\n","        55,  25,  12,  51,  21,  15,  42,  18,  13,  35,  17,   8,  36,\n","        19,  14,  25,  10,  10,  29,  11,   6,  17,   3,   2,  11,   2,\n","         5,  10,   1,   6,   7,   1,   4,   7,   1,   4,   5,   0,   3,\n","        21,  12,  10,  50,  36,  26,  39,  27,  21,  58,  28,  15,  40,\n","        14,   6,  26,  12,   6,  23,  13,   7,  21,  12,   7,  27,  18,\n","        11,  29,  16,  15,  24,   9,   6,  22,  10,   3,  24,  10,   6,\n","        25,  12,   7,  20,   8,   4,   5,  10,   3,  10,  15,   9,  21,\n","        26,  19,  15,  16,  12,  11,  10,   6,  14,   9,   6,  22,  10,\n","         2,  27,  16,   7,  25,  14,   7,  24,  13,   7,  22,  10,   4,\n","        24,  12,   7,  20,   7,   7,  20,   7,   7,  25,  12,  10,  27,\n","        13,   5,  26,  13,   5,  29,  14,   6,  32,  11,   5,  32,  12,\n","         5,  35,  16,  10,  30,  13,  10,  27,  10,   7,  27,  10,   6,\n","        26,   8,   6,  31,  13,  11,  35,  19,  18,  17,   5,   7,  11,\n","         1,   7,  10,   3,   8,   9,   3,   5,   9,   3,   5,   7,   1,\n","         3,  15,   7,   7,  31,  21,  13,  26,  13,   5,  24,   8,   7,\n","        22,   6,   4,  21,   6,   2,  20,   8,   2,  26,  13,   7,  27,\n","        16,  10,  25,  17,  10,  21,  12,   5,  17,   8,   3,  20,  11,\n","         7,  21,  12,   7,  21,  12,   8,   5,  10,   5,  14,  19,  14,\n","        23,  28,  23,  16,  17,  12,  16,  14,  11,  14,   8,   5,  21,\n","        11,   6,  18,   8,   4,  18,   8,   4,  17,   8,   4,  15,   5,\n","         1,  18,   8,   5,  18,   8,   7,  17,   7,   6,  25,  14,  12,\n","        22,  10,   5,  20,   8,   2,  21,   8,   3,  27,   9,   9,  28,\n","        10,  10,  24,   7,   6,  22,   7,   4,  22,   8,   5,  23,   8,\n","         5,  22,   7,   4,  27,  12,   9,  37,  23,  20,  18,   7,   7,\n","        12,   3,   5,  10,   4,   6,  11,   5,   5,  10,   4,   4,   7,\n","         3,   3,  12,   6,   5,  19,  11,   6,  16,   7,   4,  10,   4,\n","         6,  11,   4,   6,  15,   7,   5,  18,   8,   3,  23,  13,   9,\n","        22,  13,   7,  24,  17,   8,  21,  14,   6,  20,  12,   6,  22,\n","        13,   8,  20,  11,   5,  22,  12,   8,   4,   8,   7,  17,  22,\n","        20,  24,  29,  27,  21,  23,  19,  24,  22,  19,  14,   9,   7,\n","        17,   9,   9,  14,   6,   6,  17,   9,   8,  17,   9,   7,  12,\n","         5,   2,  16,   8,   6,  17,   9,   7,  16,   8,   6,  22,  14,\n","        12,  19,  10,   6,  18,   9,   4,  18,   8,   4,  22,   9,   7,\n","        20,   7,   5,  20,   7,   6,  20,   7,   7,  18,   5,   5,  21,\n","         8,   6,  21,   9,   5,  20,   8,   5,  31,  18,  15,  26,  15,\n","        14,  10,   2,   1,  13,   8,   8,  13,   8,   5,  11,   6,   2,\n","        10,   6,   3,  13,  10,   7,  17,  10,   9,  14,   6,   7,  10,\n","         6,   5,  10,   6,   5,  14,   8,   6,  18,  10,   7,  16,   8,\n","         6,  16,  10,   4,  17,  14,   4,  19,  15,   6,  19,  12,   5,\n","        22,  12,   7,  19,  10,   5,  20,  11,   8,   7,  10,  10,  19,\n","        22,  22,  17,  20,  19,  27,  28,  23,  37,  35,  30,  19,  14,\n","        12,  19,  14,  14,  12,   7,   7,  24,  19,  19,  16,  11,   8,\n","        14,   8,   5,  18,  12,   9,  14,   8,   5,  16,  10,   7,  19,\n","        13,  10,  17,   8,   6,  17,   7,   4,  19,  10,   5,  21,  12,\n","         6,  27,  17,   9,  29,  18,  10,  26,  14,  10,  15,   4,   3,\n","        20,   9,   7,  18,   6,   4,  21,   9,   8,  34,  22,  19,  25,\n","        12,  10,  24,  12,  10,  37,  27,  20,  19,  13,   8,   8,   5,\n","         2,   9,   6,   3,   9,   6,   4,  16,  10,  12,  14,   7,   7,\n","        11,   5,   2,  12,   5,   2,  19,  12,  10,  14,   8,   5,  11,\n","         5,   2,  11,   6,   2,  12,   9,   2,  14,  10,   3,  16,  10,\n","         4,  18,  10,   6,  18,  10,   6,  18,   9,   7,   3,   5,   4,\n","        11,  13,  12,  13,  15,  14,  28,  29,  23,  42,  41,  30,  23,\n","        18,  15,  20,  15,  12,  15,  10,   7,  20,  14,  11,  18,  10,\n","         8,  18,  10,   8,  18,  10,   8,  16,   8,   6,  20,  12,  10,\n","        19,  11,  10,  14,   6,   4,  17,  10,   4,  19,  12,   4,  22,\n","        14,   7,  32,  20,  12,  45,  31,  18,  48,  36,  21,  32,  22,\n","        17,  32,  24,  17,  32,  21,  17,  25,  15,  11,  32,  21,  15,\n","        36,  23,  16,  50,  33,  24,  50,  32,  15,  18,   8,   2,   4,\n","         4,   2,   8,   4,   2,   8,   1,   2,  14,   8,   8,   9,   4,\n","         2,  10,   5,   2,  12,   7,   4,  22,  16,  13,  13,   6,   4,\n","        14,   6,   4,  14,   8,   5,  13,   7,   5,  12,   7,   4,  16,\n","        10,   7,  17,   9,   7,  18,  10,   8,  17,   9,   7,   5,   7,\n","         6,  10,  12,  11,   8,  10,   9,  18,  20,  15,  40,  40,  27,\n","        19,  15,   7,  22,  17,  15,  17,  12,   9,  13,   8,   5,  30,\n","        22,  21,  24,  16,  14,  19,  11,   9,  18,  10,   8,  25,  17,\n","        15,  19,  12,  10,  15,   7,   5,  20,  13,   7,  23,  16,   8,\n","        24,  15,   6,  32,  21,  10,  48,  34,  18,  53,  39,  22,  33,\n","        21,  13,  28,  19,   9,  39,  31,  15,  35,  26,  11,  44,  35,\n","        17,  54,  41,  23,  48,  31,  16,  51,  33,  14,  23,  11,   5,\n","         7,   3,   2,  14,   8,   6,  12,   6,   6,  10,   5,   5,   7,\n","         2,   1,  13,   9,   4,  24,  19,  14,  18,  13,  10,  10,   5,\n","         3,  14,   9,   6,  15,  10,   7,  15,  10,   7,  12,   7,   4,\n","        17,  11,   8,  18,  10,   8,  20,  12,  10,  17,   9,   7,   3,\n","         6,   5,   8,  10,   9,   7,   9,   8,  16,  17,  13,  51,  51,\n","        34,  27,  24,  10,  32,  27,  24,  27,  21,  19,  14,   9,   6,\n","        44,  36,  34,  23,  14,  13,  15,   7,   5,  14,   6,   4,  24,\n","        16,  15,  18,  10,   8,  17,   9,   6,  17,  10,   4,  26,  19,\n","         9,  28,  20,   8,  37,  26,  12,  48,  34,  15,  46,  29,  10,\n","        34,  19,  10,  30,  19,   6,  42,  33,  16,  33,  24,   9,  33,\n","        25,   5,  45,  33,  11,  48,  31,  18,  47,  27,  14,  27,  12,\n","         7,  11,   4,   4,  11,   3,   3,  14,   8,   8,  13,   7,   7,\n","        13,   8,   5,  20,  16,   7,  27,  23,  14,  13,  10,   5,  10,\n","         8,   5,  11,   9,   5,  12,   9,   6,  16,  10,   7,  13,   8,\n","         5,  18,  11,   9,  18,  10,   8,  20,  12,  10,  14,   6,   4,\n","        12,  13,  11,  13,  13,  11,   7,   8,   7,  12,  12,  10,  49,\n","        49,  33,  41,  39,  20,  34,  30,  24,  27,  22,  19,  28,  24,\n","        19,  35,  28,  27,  20,  14,  12,  15,   8,   6,  13,   6,   4,\n","        23,  17,  15,  15,   8,   6,  15,   7,   5,  18,  10,   6,  21,\n","        13,   7,  21,  13,   1,  34,  23,  10,  41,  27,  11,  43,  27,\n","         9,  39,  24,  11,  39,  27,  11,  37,  28,  10,  30,  22,   6,\n","        37,  31,  11,  40,  28,  11,  40,  24,  16,  44,  25,  14,  31,\n","        15,   6,  16,   6,   5,  16,   8,   7,  20,  15,  12,  23,  17,\n","        15,  24,  20,  15,  19,  17,   8,  18,  16,   7,  10,   9,   4,\n","        11,  10,   6,   9,   8,   4,  11,   8,   4,  14,   9,   6,  14,\n","         9,   6,  16,  10,   8,  18,  11,   9,  17,  10,   8,  13,   6,\n","         4,  20,  19,  15,  17,  16,  12,   8,   7,   4,   8,   8,   7,\n","        33,  32,  22,  32,  29,  12,  23,  19,  11,  46,  42,  36,  32,\n","        28,  21,  23,  18,  16,  25,  20,  17,  11,   6,   4,  12,   7,\n","         4,  23,  18,  16,  10,   5,   3,  21,  13,  12,  16,   8,   7,\n","        18,  10,   7,  21,  12,   3,  27,  14,   7,  33,  19,  11,  31,\n","        18,   7,  36,  22,  11,  34,  21,   9,  31,  21,   6,  22,  15,\n","         3,  20,  15,   3,  22,  13,   4,  29,  17,   9,  45,  30,  13,\n","        37,  20,   6,  20,   8,   4,  17,  10,   8,  19,  14,   8,  21,\n","        16,  11,  17,  15,   8,  16,  16,   8,  13,  13,   6,   8,   7,\n","         2,  11,   9,   6,  10,   9,   5,  11,   8,   5,  12,   7,   4,\n","        18,  13,  10,  14,   9,   7,  17,  12,   9,  13,   8,   5,  12,\n","         7,   4,  18,  17,  13,  14,  12,   8,  10,   9,   6,   9,   9,\n","         7,  22,  21,  14,  41,  37,  26,  23,  18,  13,  52,  47,  42,\n","        54,  49,  44,  31,  26,  23,  34,  29,  27,   9,   4,   1,  12,\n","         7,   5,  24,  19,  17,  12,   7,   4,  21,  13,  12,  15,   7,\n","         6,  15,   8,   5,  13,   6,   2,  15,   4,   2,  24,  12,   8,\n","        23,  12,   8,  28,  16,  12,  27,  15,  11,  25,  13,   9,  16,\n","         7,   5,  14,   8,   7,  13,   5,   5,  24,  15,   8,  43,  29,\n","        11,  42,  24,  11,  21,  10,   6,  13,   5,   4,  16,  11,   7,\n","        16,  11,   9,   9,   5,   2,  14,  13,  10,   8,   7,   3,   7,\n","         6,   2,   9,   8,   4,   9,   9,   5,   9,   6,   3,  12,   7,\n","         4,  20,  15,  12,  13,   8,   5,  18,  13,  11,  18,  13,  10,\n","        20,  15,  12,   9,   8,   4,  10,   9,   5,  12,  11,   8,  13,\n","        14,  10,  21,  20,  15,  42,  37,  32,  33,  28,  25,  50,  45,\n","        42,  74,  69,  66,  28,  23,  21,  50,  45,  43,  10,   5,   3,\n","        21,  16,  14,  33,  28,  25,  13,   7,   4,  15,   7,   6,  22,\n","        15,  13,  20,  13,  12,  14,   9,   9,  13,   5,   5,  21,  11,\n","        10,  22,  13,   6,  26,  17,  10,  27,  17,  11,  26,  14,  11,\n","        17,   8,   8,  13,   7,   6,  11,   6,   6,  12,   5,   4,  38,\n","        25,  13,  41,  23,  11,  24,  12,   8,  10,   2,   2,  14,   9,\n","         8,  16,  11,  10,   8,   5,   3,  16,  15,  13,   8,   7,   4,\n","         7,   6,   3,   8,   7,   3,   7,   7,   2,   9,   6,   3,  15,\n","        10,   8,  19,  14,  11,  16,  11,   9,  25,  20,  17,  13,   8,\n","         5,  17,  12,   9,   5,   4,   1,   7,   6,   3,  14,  14,  11,\n","        14,  14,   9,  14,  13,  10,  28,  25,  22,  40,  36,  34,  36,\n","        32,  29,  48,  44,  42,  37,  32,  29,  80,  75,  71,  32,  28,\n","        23,  48,  46,  41,  33,  31,  26,  13,   9,   5,  17,  11,   8,\n","        30,  24,  22,  30,  23,  21,  13,   7,   7,  14,   6,   8,  21,\n","        12,  10,  24,  15,   6,  31,  21,  11,  30,  18,   9,  27,  16,\n","         9,  23,  15,  10,  16,  11,   7,  14,   9,   6,  11,   4,   6,\n","        33,  21,  15,  48,  30,  16,  26,  14,   7,   8,   3,   3,  16,\n","        10,  10,  18,  12,  13,  10,   6,   6,  16,  15,  14,   7,   6,\n","         4,   8,   7,   4,   8,   7,   3,   7,   7,   2,   9,   7,   4,\n","        23,  19,  16,  17,  13,  10,  23,  18,  15,  19,  13,  11,  14,\n","         8,   5,  16,  10,   7,   4,   4,   2,  14,  14,  12,  30,  30,\n","        28,  16,  16,  12,  19,  18,  15,  20,  19,  15,  36,  35,  32,\n","        24,  23,  20,  54,  52,  49,  76,  71,  69,  82,  77,  71,  58,\n","        55,  46,  54,  54,  47,  52,  52,  45,   9,   8,   2,  14,   9,\n","         5,  29,  25,  22,  30,  25,  21,  14,   6,   5,  16,   8,  10,\n","        22,  16,  10,  22,  13,   6,  31,  19,  10,  34,  19,  10,  28,\n","        17,   8,  26,  19,  12,  20,  14,  11,  18,  10,   8,  12,   5,\n","         4,  33,  22,  17,  50,  31,  16,  31,  18,   7,   9,   5,   3,\n","        16,  10,  10,  17,  11,  11,  15,  11,  10,  16,  15,  13,   6,\n","         5,   3,   8,   7,   4,  10,   9,   5,  11,  10,   6,  14,  11,\n","         8,  22,  17,  14,  18,  13,  10,  24,  18,  16,  17,   9,   7,\n","        17,   8,   7,  17,  11,   8,   4,   4,   2,  24,  24,  22,  37,\n","        37,  35,  13,  12,   8,  37,  36,  32,  45,  44,  41,  54,  53,\n","        50,  32,  31,  28,  67,  65,  61,  82,  78,  75,  81,  76,  72,\n","        77,  73,  66,  65,  65,  58,  56,  56,  49,  16,  15,  10,  11,\n","         6,   3,  26,  21,  19,  34,  29,  25,  23,  19,  16,  19,  14,\n","        15,  31,  26,  20,  33,  24,  16,  31,  19,  11,  34,  21,  11,\n","        27,  16,   8,  23,  16,  10,  19,  13,  10,  21,  13,  11,  14,\n","         6,   5,  29,  19,  14,  49,  31,  17,  38,  22,   8,  15,   8,\n","         5,  15,   9,   9,  19,  13,  13,  22,  18,  18,  12,  11,   9,\n","         7,   6,   4,  10,   9,   6,  12,  11,   7,  11,  10,   6,  23,\n","        20,  16,  21,  16,  13,  15,  11,   8,  18,  11,   9,  15,   7,\n","         6,  16,   8,   6,  19,  13,  10,   7,   7,   5,  24,  24,  23,\n","        35,  35,  33,  17,  16,  13,  45,  44,  41,  34,  33,  30,  56,\n","        55,  51,  37,  37,  33,  63,  61,  58,  72,  67,  64,  74,  69,\n","        65,  77,  74,  65,  73,  72,  66,  42,  43,  37,  32,  31,  26,\n","        11,   6,   3,  27,  22,  20,  42,  38,  34,  37,  36,  32,  22,\n","        20,  20,  27,  25,  18,  30,  21,  14,  34,  22,  13,  33,  19,\n","         9,  28,  17,   8,  23,  15,   9,  24,  18,  15,  17,   9,   8,\n","        14,   6,   5,  26,  17,  13,  39,  22,  10,  46,  26,   8,  25,\n","        14,   8,  17,  12,  12,  26,  20,  21,  22,  19,  18,   8,   7,\n","         6,   8,   7,   5,  10,   9,   7,  14,  13,   9,  16,  15,  11,\n","        18,  16,  12,  21,  16,  14,  12,   7,   5,  23,  16,  14,  17,\n","         9,   7,  18,   9,   8,  20,  14,  11,   9,   9,   6,  25,  26,\n","        20,  40,  40,  37,  18,  18,  13,  37,  36,  31,  30,  29,  25,\n","        50,  50,  47,  36,  36,  32,  66,  65,  61,  66,  61,  56,  88,\n","        84,  79,  97,  93,  85,  77,  75,  68,  28,  25,  20,  45,  42,\n","        36,  12,   6,   4,  21,  16,  14,  46,  43,  40,  50,  50,  45,\n","        28,  26,  24,  28,  25,  17,  27,  19,   9,  32,  22,  11,  33,\n","        19,   9,  28,  17,   8,  23,  15,   9,  30,  24,  19,  23,  15,\n","        11,  13,   5,   4,  30,  20,  15,  38,  21,  10,  48,  27,  10,\n","        34,  19,   9,  16,   9,   7,  25,  19,  17,  21,  18,  15,   6,\n","         5,   3,  10,   9,   7,  15,  14,  11,  15,  13,   9,  22,  20,\n","        17,  18,  14,  11,  17,  11,   9,  15,  10,   8,  24,  18,  16,\n","        13,   6,   6,  20,  13,  12,  14,   9,   6], dtype=uint8)"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","source":[""],"metadata":{"id":"dCItvZ_xjvzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"3weJfw_5kDob"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","machine_shape":"hm","name":"Copy of custom_cnn3.ipynb","provenance":[],"collapsed_sections":["uN6C5uhzTcav","lx3VD0bqZ8fX","HjagyiZlgr4i","UftMvxqmZ-_g","aXvkchFoWrDX","lrVIgCDnsS3-","FE8mYSKMgRpP","7H1wNq2pHGPD","KiQlOB7ut5pH","R9YYvxuWDMsg","0MfCJoZrMnzB","-1XEE0UlZl2C","OmxBPoLnjX2p"],"authorship_tag":"ABX9TyMd+llpQyvgb951xHZUdUln"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}