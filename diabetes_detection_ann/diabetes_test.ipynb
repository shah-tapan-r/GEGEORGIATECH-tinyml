{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNfxqaiiwG-i"
      },
      "source": [
        "# **Data Parsing & Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0dhTza5xBYE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438d0f07-0aa4-445d-bdee-aa4aea167c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDfKcYpF16pO",
        "outputId": "2caf7b9a-3518-43f4-999c-e3fc968fdfbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --versions\n",
        "print('Numpy ' + np.__version__)\n",
        "print('TensorFlow ' + tf.__version__)\n",
        "print('Keras ' + tf.keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLqLsQmz-K6p",
        "outputId": "5b7c1a89-33af-4294-b6e4-622d360bfdac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unknown option --versions\n",
            "usage: python3 [option] ... [-c cmd | -m mod | file | -] [arg] ...\n",
            "Try `python -h' for more information.\n",
            "Numpy 1.21.6\n",
            "TensorFlow 2.8.2\n",
            "Keras 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aIA2YEv8BgRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "609d9dd1-e458-4c7f-859f-10cb05d0505f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "#Check if your present working directory has changed to the path specified in the previous cel.\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_model_name = 'test_model'\n",
        "tflite_model_name = 'test_model' "
      ],
      "metadata": {
        "id": "u1Q6a5LEAI_w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q4Q0D7kC4gK"
      },
      "source": [
        "# **Diabetes dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = loadtxt(\"drive/MyDrive/diabetes.csv\", delimiter=\",\", skiprows=1)\n",
        "\n",
        "x_train = df[0:int(0.6*len(df)),0:8]\n",
        "y_train = df[0:int(0.6*len(df)),8]\n",
        "\n",
        "x_test = df[int(0.6*len(df)):,0:8]\n",
        "y_test = df[int(0.6*len(df)):,8]"
      ],
      "metadata": {
        "id": "Fp8nMX-n2zyU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creation of the original model**"
      ],
      "metadata": {
        "id": "U0YQlJ5Sb1cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation = 'relu'))\n",
        "model.add(Dense(8,activation = 'relu'))\n",
        "model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "# opt = tf.keras.optimizers.Adam(lr = 1e-3,decay = 1e-5)\n",
        "model.compile(optimizer = 'adam',loss = \"binary_crossentropy\" , metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,epochs = 150,validation_data = (x_test,y_test), batch_size=10)\n",
        "\n",
        "model.save('model1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCjw5fmj3GVu",
        "outputId": "26e54dbb-9378-48c5-91d3-ca934ae77547"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "46/46 [==============================] - 1s 6ms/step - loss: 23.5898 - accuracy: 0.6196 - val_loss: 9.4086 - val_accuracy: 0.6981\n",
            "Epoch 2/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 5.5436 - accuracy: 0.5609 - val_loss: 1.5163 - val_accuracy: 0.4838\n",
            "Epoch 3/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 1.3750 - accuracy: 0.4326 - val_loss: 1.0499 - val_accuracy: 0.4383\n",
            "Epoch 4/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.9621 - accuracy: 0.4891 - val_loss: 0.8967 - val_accuracy: 0.4870\n",
            "Epoch 5/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.8192 - accuracy: 0.5913 - val_loss: 0.8306 - val_accuracy: 0.6299\n",
            "Epoch 6/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.7830 - accuracy: 0.6109 - val_loss: 0.7659 - val_accuracy: 0.6883\n",
            "Epoch 7/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.7577 - accuracy: 0.6174 - val_loss: 0.7375 - val_accuracy: 0.6851\n",
            "Epoch 8/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.6196 - val_loss: 0.7092 - val_accuracy: 0.6948\n",
            "Epoch 9/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.6217 - val_loss: 0.6903 - val_accuracy: 0.6981\n",
            "Epoch 10/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.7232 - accuracy: 0.6217 - val_loss: 0.6886 - val_accuracy: 0.6981\n",
            "Epoch 11/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.7134 - accuracy: 0.6239 - val_loss: 0.6752 - val_accuracy: 0.6981\n",
            "Epoch 12/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.6196 - val_loss: 0.6624 - val_accuracy: 0.6981\n",
            "Epoch 13/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.6196 - val_loss: 0.6572 - val_accuracy: 0.6981\n",
            "Epoch 14/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.6196 - val_loss: 0.6598 - val_accuracy: 0.6981\n",
            "Epoch 15/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.6196 - val_loss: 0.6575 - val_accuracy: 0.6981\n",
            "Epoch 16/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.6196 - val_loss: 0.6577 - val_accuracy: 0.6981\n",
            "Epoch 17/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.6196 - val_loss: 0.6578 - val_accuracy: 0.6981\n",
            "Epoch 18/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.6196 - val_loss: 0.6547 - val_accuracy: 0.6981\n",
            "Epoch 19/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.6196 - val_loss: 0.6526 - val_accuracy: 0.6981\n",
            "Epoch 20/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.6196 - val_loss: 0.6513 - val_accuracy: 0.6981\n",
            "Epoch 21/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6196 - val_loss: 0.6522 - val_accuracy: 0.6981\n",
            "Epoch 22/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6196 - val_loss: 0.6501 - val_accuracy: 0.6981\n",
            "Epoch 23/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6196 - val_loss: 0.6507 - val_accuracy: 0.6981\n",
            "Epoch 24/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.6196 - val_loss: 0.6507 - val_accuracy: 0.6981\n",
            "Epoch 25/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6196 - val_loss: 0.6478 - val_accuracy: 0.6981\n",
            "Epoch 26/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6196 - val_loss: 0.6477 - val_accuracy: 0.6981\n",
            "Epoch 27/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.6196 - val_loss: 0.6471 - val_accuracy: 0.6981\n",
            "Epoch 28/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.6196 - val_loss: 0.6461 - val_accuracy: 0.6981\n",
            "Epoch 29/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.6196 - val_loss: 0.6428 - val_accuracy: 0.6981\n",
            "Epoch 30/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6196 - val_loss: 0.6436 - val_accuracy: 0.6981\n",
            "Epoch 31/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.6196 - val_loss: 0.6445 - val_accuracy: 0.6981\n",
            "Epoch 32/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.6196 - val_loss: 0.6392 - val_accuracy: 0.6981\n",
            "Epoch 33/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6196 - val_loss: 0.6411 - val_accuracy: 0.6981\n",
            "Epoch 34/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6196 - val_loss: 0.6460 - val_accuracy: 0.6981\n",
            "Epoch 35/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6196 - val_loss: 0.6414 - val_accuracy: 0.6981\n",
            "Epoch 36/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6196 - val_loss: 0.6388 - val_accuracy: 0.6981\n",
            "Epoch 37/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6196 - val_loss: 0.6356 - val_accuracy: 0.6981\n",
            "Epoch 38/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6196 - val_loss: 0.6404 - val_accuracy: 0.6981\n",
            "Epoch 39/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6196 - val_loss: 0.6348 - val_accuracy: 0.6981\n",
            "Epoch 40/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6196 - val_loss: 0.6348 - val_accuracy: 0.6981\n",
            "Epoch 41/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6196 - val_loss: 0.6373 - val_accuracy: 0.6981\n",
            "Epoch 42/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6196 - val_loss: 0.6316 - val_accuracy: 0.6981\n",
            "Epoch 43/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6196 - val_loss: 0.6303 - val_accuracy: 0.6981\n",
            "Epoch 44/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6196 - val_loss: 0.6296 - val_accuracy: 0.6981\n",
            "Epoch 45/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6196 - val_loss: 0.6323 - val_accuracy: 0.6981\n",
            "Epoch 46/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6196 - val_loss: 0.6250 - val_accuracy: 0.6981\n",
            "Epoch 47/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6196 - val_loss: 0.6255 - val_accuracy: 0.6981\n",
            "Epoch 48/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.6196 - val_loss: 0.6212 - val_accuracy: 0.6981\n",
            "Epoch 49/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6196 - val_loss: 0.6177 - val_accuracy: 0.6981\n",
            "Epoch 50/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.6196 - val_loss: 0.6223 - val_accuracy: 0.6981\n",
            "Epoch 51/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6196 - val_loss: 0.6232 - val_accuracy: 0.6981\n",
            "Epoch 52/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6196 - val_loss: 0.6170 - val_accuracy: 0.6981\n",
            "Epoch 53/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6196 - val_loss: 0.6113 - val_accuracy: 0.6981\n",
            "Epoch 54/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6196 - val_loss: 0.6138 - val_accuracy: 0.6981\n",
            "Epoch 55/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6196 - val_loss: 0.6169 - val_accuracy: 0.6981\n",
            "Epoch 56/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6196 - val_loss: 0.6113 - val_accuracy: 0.6981\n",
            "Epoch 57/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6196 - val_loss: 0.6156 - val_accuracy: 0.6981\n",
            "Epoch 58/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6196 - val_loss: 0.6021 - val_accuracy: 0.6981\n",
            "Epoch 59/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6196 - val_loss: 0.6088 - val_accuracy: 0.6981\n",
            "Epoch 60/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6196 - val_loss: 0.6010 - val_accuracy: 0.6981\n",
            "Epoch 61/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6196 - val_loss: 0.6035 - val_accuracy: 0.6981\n",
            "Epoch 62/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6196 - val_loss: 0.5912 - val_accuracy: 0.6981\n",
            "Epoch 63/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6196 - val_loss: 0.6080 - val_accuracy: 0.6981\n",
            "Epoch 64/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6196 - val_loss: 0.6071 - val_accuracy: 0.6981\n",
            "Epoch 65/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.6196 - val_loss: 0.5997 - val_accuracy: 0.6981\n",
            "Epoch 66/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6196 - val_loss: 0.6324 - val_accuracy: 0.6981\n",
            "Epoch 67/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6196 - val_loss: 0.5910 - val_accuracy: 0.6981\n",
            "Epoch 68/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6196 - val_loss: 0.5990 - val_accuracy: 0.6981\n",
            "Epoch 69/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6196 - val_loss: 0.5925 - val_accuracy: 0.6981\n",
            "Epoch 70/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.6196 - val_loss: 0.5877 - val_accuracy: 0.6981\n",
            "Epoch 71/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.6196 - val_loss: 0.5855 - val_accuracy: 0.6981\n",
            "Epoch 72/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6196 - val_loss: 0.5816 - val_accuracy: 0.6981\n",
            "Epoch 73/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6196 - val_loss: 0.5795 - val_accuracy: 0.6981\n",
            "Epoch 74/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.6196 - val_loss: 0.5938 - val_accuracy: 0.6981\n",
            "Epoch 75/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6196 - val_loss: 0.5932 - val_accuracy: 0.6981\n",
            "Epoch 76/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6196 - val_loss: 0.5828 - val_accuracy: 0.6981\n",
            "Epoch 77/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6196 - val_loss: 0.5902 - val_accuracy: 0.6981\n",
            "Epoch 78/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.6196 - val_loss: 0.5951 - val_accuracy: 0.6981\n",
            "Epoch 79/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6196 - val_loss: 0.5987 - val_accuracy: 0.6981\n",
            "Epoch 80/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6196 - val_loss: 0.5942 - val_accuracy: 0.6981\n",
            "Epoch 81/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6196 - val_loss: 0.5776 - val_accuracy: 0.6981\n",
            "Epoch 82/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.6196 - val_loss: 0.5739 - val_accuracy: 0.6981\n",
            "Epoch 83/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.6196 - val_loss: 0.5735 - val_accuracy: 0.6981\n",
            "Epoch 84/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6196 - val_loss: 0.5875 - val_accuracy: 0.6981\n",
            "Epoch 85/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6196 - val_loss: 0.5775 - val_accuracy: 0.6981\n",
            "Epoch 86/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6196 - val_loss: 0.5934 - val_accuracy: 0.6981\n",
            "Epoch 87/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6196 - val_loss: 0.5734 - val_accuracy: 0.6981\n",
            "Epoch 88/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.6196 - val_loss: 0.5678 - val_accuracy: 0.6981\n",
            "Epoch 89/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6196 - val_loss: 0.6034 - val_accuracy: 0.6981\n",
            "Epoch 90/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6196 - val_loss: 0.5888 - val_accuracy: 0.6981\n",
            "Epoch 91/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6196 - val_loss: 0.5779 - val_accuracy: 0.6981\n",
            "Epoch 92/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6196 - val_loss: 0.6035 - val_accuracy: 0.6981\n",
            "Epoch 93/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.6196 - val_loss: 0.6024 - val_accuracy: 0.6981\n",
            "Epoch 94/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6196 - val_loss: 0.5942 - val_accuracy: 0.6981\n",
            "Epoch 95/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6196 - val_loss: 0.5783 - val_accuracy: 0.6981\n",
            "Epoch 96/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6196 - val_loss: 0.5764 - val_accuracy: 0.6981\n",
            "Epoch 97/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6196 - val_loss: 0.5972 - val_accuracy: 0.6981\n",
            "Epoch 98/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6196 - val_loss: 0.5948 - val_accuracy: 0.6981\n",
            "Epoch 99/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6196 - val_loss: 0.5680 - val_accuracy: 0.6981\n",
            "Epoch 100/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.6196 - val_loss: 0.5612 - val_accuracy: 0.6981\n",
            "Epoch 101/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.6196 - val_loss: 0.5815 - val_accuracy: 0.6981\n",
            "Epoch 102/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.6196 - val_loss: 0.5833 - val_accuracy: 0.6981\n",
            "Epoch 103/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6196 - val_loss: 0.5926 - val_accuracy: 0.6981\n",
            "Epoch 104/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6196 - val_loss: 0.5645 - val_accuracy: 0.6981\n",
            "Epoch 105/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.6196 - val_loss: 0.5719 - val_accuracy: 0.6981\n",
            "Epoch 106/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6196 - val_loss: 0.5859 - val_accuracy: 0.6981\n",
            "Epoch 107/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6196 - val_loss: 0.5686 - val_accuracy: 0.6981\n",
            "Epoch 108/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.6196 - val_loss: 0.6067 - val_accuracy: 0.6981\n",
            "Epoch 109/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6196 - val_loss: 0.5974 - val_accuracy: 0.6981\n",
            "Epoch 110/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6196 - val_loss: 0.5743 - val_accuracy: 0.6981\n",
            "Epoch 111/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.6196 - val_loss: 0.5696 - val_accuracy: 0.6981\n",
            "Epoch 112/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6015 - accuracy: 0.6196 - val_loss: 0.5815 - val_accuracy: 0.6981\n",
            "Epoch 113/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.6196 - val_loss: 0.5846 - val_accuracy: 0.6981\n",
            "Epoch 114/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.6196 - val_loss: 0.5852 - val_accuracy: 0.6981\n",
            "Epoch 115/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.6196 - val_loss: 0.5776 - val_accuracy: 0.6981\n",
            "Epoch 116/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.6196 - val_loss: 0.5855 - val_accuracy: 0.6981\n",
            "Epoch 117/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.6196 - val_loss: 0.5709 - val_accuracy: 0.6981\n",
            "Epoch 118/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.6196 - val_loss: 0.5906 - val_accuracy: 0.6981\n",
            "Epoch 119/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6196 - val_loss: 0.6017 - val_accuracy: 0.6981\n",
            "Epoch 120/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.6196 - val_loss: 0.5742 - val_accuracy: 0.6981\n",
            "Epoch 121/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.6435 - val_loss: 0.5863 - val_accuracy: 0.6266\n",
            "Epoch 122/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.6609 - val_loss: 0.5711 - val_accuracy: 0.6656\n",
            "Epoch 123/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.6587 - val_loss: 0.5828 - val_accuracy: 0.6429\n",
            "Epoch 124/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.6609 - val_loss: 0.5798 - val_accuracy: 0.6558\n",
            "Epoch 125/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.6609 - val_loss: 0.5817 - val_accuracy: 0.6364\n",
            "Epoch 126/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.6500 - val_loss: 0.5697 - val_accuracy: 0.6818\n",
            "Epoch 127/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.6674 - val_loss: 0.5717 - val_accuracy: 0.6721\n",
            "Epoch 128/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.6696 - val_loss: 0.5649 - val_accuracy: 0.7045\n",
            "Epoch 129/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6543 - val_loss: 0.5824 - val_accuracy: 0.6461\n",
            "Epoch 130/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.6522 - val_loss: 0.5869 - val_accuracy: 0.6299\n",
            "Epoch 131/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6543 - val_loss: 0.5724 - val_accuracy: 0.6623\n",
            "Epoch 132/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.6609 - val_loss: 0.5659 - val_accuracy: 0.6981\n",
            "Epoch 133/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6652 - val_loss: 0.5772 - val_accuracy: 0.6623\n",
            "Epoch 134/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.6674 - val_loss: 0.5667 - val_accuracy: 0.7013\n",
            "Epoch 135/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6696 - val_loss: 0.5684 - val_accuracy: 0.6883\n",
            "Epoch 136/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6609 - val_loss: 0.5893 - val_accuracy: 0.6396\n",
            "Epoch 137/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6674 - val_loss: 0.5711 - val_accuracy: 0.6948\n",
            "Epoch 138/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.6674 - val_loss: 0.5682 - val_accuracy: 0.6948\n",
            "Epoch 139/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6522 - val_loss: 0.5898 - val_accuracy: 0.6234\n",
            "Epoch 140/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.6587 - val_loss: 0.5954 - val_accuracy: 0.6104\n",
            "Epoch 141/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6630 - val_loss: 0.5726 - val_accuracy: 0.6623\n",
            "Epoch 142/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.6674 - val_loss: 0.5714 - val_accuracy: 0.6818\n",
            "Epoch 143/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.6609 - val_loss: 0.5767 - val_accuracy: 0.6623\n",
            "Epoch 144/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.6565 - val_loss: 0.5849 - val_accuracy: 0.6494\n",
            "Epoch 145/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.6609 - val_loss: 0.5718 - val_accuracy: 0.6591\n",
            "Epoch 146/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.6435 - val_loss: 0.5793 - val_accuracy: 0.6558\n",
            "Epoch 147/150\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.6652 - val_loss: 0.5851 - val_accuracy: 0.6299\n",
            "Epoch 148/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.6674 - val_loss: 0.5746 - val_accuracy: 0.6623\n",
            "Epoch 149/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6761 - val_loss: 0.5987 - val_accuracy: 0.6006\n",
            "Epoch 150/150\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.6696 - val_loss: 0.5717 - val_accuracy: 0.6623\n",
            "INFO:tensorflow:Assets written to: model1/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(x_test)\n",
        "print(len(res))\n",
        "classes = [int(res[i][0]*2) for i in range(len(res))]\n",
        "print(classes)\n",
        "acc = sum([classes[i] == y_test[i] for i in range(len(y_test))])/len(y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duWkShDVpEcp",
        "outputId": "abf785ff-85cb-4836-a6d2-17af3253bf60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "308\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0]\n",
            "0.6623376623376623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Quantization**"
      ],
      "metadata": {
        "id": "IipRJEZDcERk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion to bytes \n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [\n",
        "tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EPQaBij8J1T",
        "outputId": "59e0900b-4bf1-4b30-f532-8766b025ee01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmptu49u7pz/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2800"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Convert some hex value into an array for C programming\n",
        "def hex_to_c_array(hex_data, var_name):\n",
        "\n",
        "  c_str = ''\n",
        "\n",
        "  # Create header guard\n",
        "  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
        "  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
        "\n",
        "  # Add array length at top of file\n",
        "  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
        "\n",
        "  # Declare C variable\n",
        "  c_str += 'unsigned char ' + var_name + '[] = {'\n",
        "  hex_array = []\n",
        "  for i, val in enumerate(hex_data) :\n",
        "\n",
        "    # Construct string from hex\n",
        "    hex_str = format(val, '#04x')\n",
        "\n",
        "    # Add formatting so each line stays within 80 characters\n",
        "    if (i + 1) < len(hex_data):\n",
        "      hex_str += ','\n",
        "    if (i + 1) % 12 == 0:\n",
        "      hex_str += '\\n '\n",
        "    hex_array.append(hex_str)\n",
        "\n",
        "  # Add closing brace\n",
        "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
        "\n",
        "  # Close out header guard\n",
        "  c_str += '#endif //' + var_name.upper() + '_H'\n",
        "\n",
        "  return c_str"
      ],
      "metadata": {
        "id": "dM3ekIhi_w26"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write TFLite model to a C source (or header) file\n",
        "with open(c_model_name + '.h', 'w') as file:\n",
        "  file.write(hex_to_c_array(tflite_model, c_model_name))\n",
        "\n"
      ],
      "metadata": {
        "id": "7U7aa0_A_zy4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.lite.experimental.Analyzer.analyze(model_content=tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCLzfKMT6k0W",
        "outputId": "dfb47ba8-3e16-4466-9574-ae0e8f375073"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TFLite ModelAnalyzer ===\n",
            "\n",
            "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
            "T# represents the Tensor numbers. For example, in Subgraph#0, the FULLY_CONNECTED op takes\n",
            "tensor #0 and tensor #4 and tensor #3 as input and produces tensor #7 as output.\n",
            "\n",
            "Subgraph#0 main(T#0) -> [T#10]\n",
            "  Op#0 FULLY_CONNECTED(T#0, T#4, T#3) -> [T#7]\n",
            "  Op#1 FULLY_CONNECTED(T#7, T#5, T#2) -> [T#8]\n",
            "  Op#2 FULLY_CONNECTED(T#8, T#6, T#1) -> [T#9]\n",
            "  Op#3 LOGISTIC(T#9) -> [T#10]\n",
            "\n",
            "Tensors of Subgraph#0\n",
            "  T#0(serving_default_dense_input:0) shape_signature:[-1, 8], type:FLOAT32\n",
            "  T#1(dense_2/bias) shape:[1], type:FLOAT32 RO 4 bytes\n",
            "  T#2(dense_1/bias) shape:[8], type:FLOAT32 RO 32 bytes\n",
            "  T#3(dense/bias) shape:[12], type:FLOAT32 RO 48 bytes\n",
            "  T#4(sequential/dense/MatMul) shape:[12, 8], type:FLOAT32 RO 384 bytes\n",
            "  T#5(sequential/dense_1/MatMul) shape:[8, 12], type:FLOAT32 RO 384 bytes\n",
            "  T#6(sequential/dense_2/MatMul) shape:[1, 8], type:FLOAT32 RO 32 bytes\n",
            "  T#7(sequential/dense/MatMul;sequential/dense/Relu;sequential/dense/BiasAdd) shape_signature:[-1, 12], type:FLOAT32\n",
            "  T#8(sequential/dense_1/MatMul;sequential/dense_1/Relu;sequential/dense_1/BiasAdd) shape_signature:[-1, 8], type:FLOAT32\n",
            "  T#9(sequential/dense_2/MatMul;sequential/dense_2/BiasAdd) shape_signature:[-1, 1], type:FLOAT32\n",
            "  T#10(StatefulPartitionedCall:0) shape_signature:[-1, 1], type:FLOAT32\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Your TFLite model has ‘1’ signature_def(s).\n",
            "\n",
            "Signature#0 key: 'serving_default'\n",
            "- Subgraph: Subgraph#0\n",
            "- Inputs: \n",
            "    'dense_input' : T#0\n",
            "- Outputs: \n",
            "    'dense_2' : T#10\n",
            "\n",
            "---------------------------------------------------------------\n",
            "              Model size:       2800 bytes\n",
            "    Non-data buffer size:       1900 bytes (67.86 %)\n",
            "  Total data buffer size:        900 bytes (32.14 %)\n",
            "    (Zero value buffers):          0 bytes (00.00 %)\n",
            "\n",
            "* Buffers of TFLite model are mostly used for constant tensors.\n",
            "  And zero value buffers are buffers filled with zeros.\n",
            "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
            "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/model1.zip /content/model1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4tkIpEhLYM8",
        "outputId": "1e143e91-bbf5-4d50-b4d5-424f26941ba8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/model1/ (stored 0%)\n",
            "  adding: content/model1/variables/ (stored 0%)\n",
            "  adding: content/model1/variables/variables.index (deflated 63%)\n",
            "  adding: content/model1/variables/variables.data-00000-of-00001 (deflated 58%)\n",
            "  adding: content/model1/keras_metadata.pb (deflated 87%)\n",
            "  adding: content/model1/assets/ (stored 0%)\n",
            "  adding: content/model1/saved_model.pb (deflated 88%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "input_details = interpreter.get_input_details()\n",
        "# interpreter.resize_tensor_input(input_details[0][\"index\"], i1test.shape)\n",
        "interpreter.allocate_tensors()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "#Predictions from TFLite model\n",
        "tfl_pred = []\n",
        "tfl_pred_class = []\n",
        "for i in range(len(x_test)):\n",
        "    interpreter.set_tensor(input_details[0][\"index\"], x_test.astype('float32')[i:i+1,:])\n",
        "    interpreter.invoke()\n",
        "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "    tfl_pred.append(result)\n",
        "    tfl_pred_class.append(int(result[0]*2))\n",
        "print(tfl_pred_class)\n",
        "print(tfl_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y96PWMMlRYGD",
        "outputId": "f1cedba5-8ed4-4099-abd4-be7faf77dc28"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0]\n",
            "[array([[0.51333725]], dtype=float32), array([[0.16844681]], dtype=float32), array([[0.24068213]], dtype=float32), array([[0.14929269]], dtype=float32), array([[0.1047475]], dtype=float32), array([[0.28612655]], dtype=float32), array([[0.25781852]], dtype=float32), array([[0.26791304]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.351862]], dtype=float32), array([[0.36569452]], dtype=float32), array([[0.3876422]], dtype=float32), array([[0.44100356]], dtype=float32), array([[0.5036186]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.48239318]], dtype=float32), array([[0.39310393]], dtype=float32), array([[0.21776554]], dtype=float32), array([[0.33448416]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.10338342]], dtype=float32), array([[0.29683858]], dtype=float32), array([[0.18082482]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.21581703]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.19836067]], dtype=float32), array([[0.0695562]], dtype=float32), array([[0.3575126]], dtype=float32), array([[0.49687824]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.47018915]], dtype=float32), array([[0.15622729]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.02352948]], dtype=float32), array([[0.18285154]], dtype=float32), array([[0.03766947]], dtype=float32), array([[0.47848168]], dtype=float32), array([[0.23856537]], dtype=float32), array([[0.01123487]], dtype=float32), array([[0.29150334]], dtype=float32), array([[0.45101276]], dtype=float32), array([[0.3653607]], dtype=float32), array([[0.4598769]], dtype=float32), array([[0.48106176]], dtype=float32), array([[0.45559087]], dtype=float32), array([[0.09073863]], dtype=float32), array([[0.3169096]], dtype=float32), array([[0.31305164]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.48626065]], dtype=float32), array([[0.02028714]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.08751762]], dtype=float32), array([[0.16913664]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.23694094]], dtype=float32), array([[0.08875871]], dtype=float32), array([[0.1402323]], dtype=float32), array([[0.44588003]], dtype=float32), array([[0.4354315]], dtype=float32), array([[0.3261323]], dtype=float32), array([[0.31674543]], dtype=float32), array([[0.16788241]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.22844224]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.13161759]], dtype=float32), array([[0.01349396]], dtype=float32), array([[0.37446404]], dtype=float32), array([[0.15663873]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.37651885]], dtype=float32), array([[0.05400036]], dtype=float32), array([[0.09170521]], dtype=float32), array([[0.46807396]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51091623]], dtype=float32), array([[0.17980668]], dtype=float32), array([[0.22280832]], dtype=float32), array([[0.29361543]], dtype=float32), array([[0.2968691]], dtype=float32), array([[0.1758169]], dtype=float32), array([[0.47566321]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.2614772]], dtype=float32), array([[0.29252413]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.10460608]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.17082454]], dtype=float32), array([[0.44073462]], dtype=float32), array([[0.10307658]], dtype=float32), array([[0.32726017]], dtype=float32), array([[0.1643825]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.45281637]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.068771]], dtype=float32), array([[0.04532358]], dtype=float32), array([[0.40597284]], dtype=float32), array([[0.4593145]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.2958009]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.16835979]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.137242]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.35076025]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.45035723]], dtype=float32), array([[0.44162855]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.2131274]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.1672547]], dtype=float32), array([[0.00499448]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.04968104]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.26696736]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.1417132]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.50020665]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.18267848]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.27014804]], dtype=float32), array([[0.08752938]], dtype=float32), array([[0.10272478]], dtype=float32), array([[0.48058432]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.23444879]], dtype=float32), array([[0.11517474]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.32979178]], dtype=float32), array([[0.41941118]], dtype=float32), array([[0.03627187]], dtype=float32), array([[0.34517652]], dtype=float32), array([[0.2759262]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.22042961]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.07238407]], dtype=float32), array([[0.5122088]], dtype=float32), array([[0.2082287]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.31333715]], dtype=float32), array([[0.49009052]], dtype=float32), array([[0.08232599]], dtype=float32), array([[0.33085054]], dtype=float32), array([[0.0789846]], dtype=float32), array([[0.08680895]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.33574045]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.28763333]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.2894512]], dtype=float32), array([[0.35323834]], dtype=float32), array([[0.30551445]], dtype=float32), array([[0.35538548]], dtype=float32), array([[0.22116028]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.2782578]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.15073013]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.19202496]], dtype=float32), array([[0.09058911]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.357147]], dtype=float32), array([[0.37563017]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.13508312]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.3797239]], dtype=float32), array([[0.06992576]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.00754831]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.45256075]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.13624087]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.35198715]], dtype=float32), array([[0.3353972]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.5091989]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.22620313]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.29445133]], dtype=float32), array([[0.339899]], dtype=float32), array([[0.22289479]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.3353971]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.4426761]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.2689562]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.14901818]], dtype=float32), array([[0.11578112]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.3969437]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.2910343]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.32003862]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.48601454]], dtype=float32), array([[0.06401211]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.47113013]], dtype=float32), array([[0.23814128]], dtype=float32), array([[0.13455822]], dtype=float32), array([[0.36496958]], dtype=float32), array([[0.37763235]], dtype=float32), array([[0.1797969]], dtype=float32), array([[0.32090503]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.20073493]], dtype=float32), array([[0.18128444]], dtype=float32), array([[0.21993607]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.4547421]], dtype=float32), array([[0.5033335]], dtype=float32), array([[0.05058307]], dtype=float32), array([[0.16203523]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.31467634]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.3299626]], dtype=float32), array([[0.4754996]], dtype=float32), array([[0.4297861]], dtype=float32), array([[0.35665995]], dtype=float32), array([[0.21523292]], dtype=float32), array([[0.17337656]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.14096907]], dtype=float32), array([[0.40863124]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.10356598]], dtype=float32), array([[0.28850546]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.2604771]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.29016864]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.4588641]], dtype=float32), array([[0.21569256]], dtype=float32), array([[0.51333725]], dtype=float32), array([[0.14493787]], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)\n",
        "print(len(y_test))\n",
        "\n",
        "right_pred = [y_test[i] == tfl_pred_class[i] for i in range(len(y_test))]\n",
        "print(right_pred)\n",
        "acc = sum(right_pred)/len(right_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH7LIgb7UYO6",
        "outputId": "3afdc47a-a108-48a2-fcfc-2f495077a80b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
            "308\n",
            "[False, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, False, True, True, False, True, True, True, True, True, True, False, False, True, False, True, True, True, False, False, False, True, True, True, False, True, True, False, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, False, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, False, True, True, False, True, False, False, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, False, False, False, True, False, False, False, True, True, True, True, True, False, False, True, True, True, False, False, False, True, False, True, False, True, False, True, True, True, False, True, True, False, False, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, True, True, True, False, True, False, False, True, True, False, True, True, False, True, False, True, False, False, True, False, True, True, True, True, False, True, True, True, False, True, False, False, True, False, False, True, True, True, True, False, False, False, True, True, False, True, True, True, True, True, False, True, True, True, False, False, False, False, False, True, True, True, False, True, True, True, True, False, False, True, False, False, True, True, False, True, True, True, False, True, True, False, True, True, False, True, True, False, False, False, False, True, False, False, True, True, True, True, True, True, False, False, False, False, False, True, False, True, True, False, False, True, False, True, False, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, True, True, True, True]\n",
            "0.6623376623376623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering**"
      ],
      "metadata": {
        "id": "a-0vKLVvcL0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-model-optimization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjcC4UrMTq1E",
        "outputId": "45667c79-94db-409f-90d7-12426bff2faf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 36.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 38.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 102 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 153 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 174 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 184 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 204 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 215 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 225 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 235 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 237 kB 20.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
        "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
        "\n",
        "clustering_params = {\n",
        "  'number_of_clusters': 16,\n",
        "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
        "}\n",
        "\n",
        "# Cluster a whole model\n",
        "clustered_model = cluster_weights(model, **clustering_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning clustered model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "clustered_model.compile(\n",
        "  loss=\"binary_crossentropy\",\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "clustered_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpzhWe_RTyAi",
        "outputId": "46e1d373-7ecd-4053-d03f-ecc36b3b0391"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " cluster_dense (ClusterWeigh  (None, 12)               220       \n",
            " ts)                                                             \n",
            "                                                                 \n",
            " cluster_dense_1 (ClusterWei  (None, 8)                216       \n",
            " ghts)                                                           \n",
            "                                                                 \n",
            " cluster_dense_2 (ClusterWei  (None, 1)                33        \n",
            " ghts)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 469\n",
            "Trainable params: 269\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune model\n",
        "clustered_model.fit(x_train,y_train,epochs = 1,validation_data = (x_test,y_test), batch_size=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqI7t9ZOUgtF",
        "outputId": "9715f3ec-c5d6-4af4-e023-2ae291839d40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 1s 12ms/step - loss: 0.5962 - accuracy: 0.6565 - val_loss: 0.5645 - val_accuracy: 0.6721\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc9ec24cc50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
        "\n",
        "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving clustered model to: ', clustered_keras_file)\n",
        "tf.keras.models.save_model(final_model, clustered_keras_file, \n",
        "                           include_optimizer=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XadNHnRlXUpE",
        "outputId": "fb602ada-f9ec-4190-e632-909674e5b148"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving clustered model to:  /tmp/tmp3urxxztw.h5\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen():\n",
        "    for i_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(117):\n",
        "      i_value_f32 = tf.dtypes.cast(i_value,tf.float32)\n",
        "      yield [i_value_f32]"
      ],
      "metadata": {
        "id": "GkRTk7Z6Te4A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_tflite_file = 'clustered_quantized.tflite'\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "tflite_clustered_model = converter.convert()\n",
        "with open(clustered_tflite_file, 'wb') as f:\n",
        "  f.write(tflite_clustered_model)\n",
        "print('Saved clustered TFLite model to:', clustered_tflite_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye1DuBBEXm3q",
        "outputId": "5bb6fe70-9205-4b12-dae6-b4a033fa96a4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpb4mu4p35/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpb4mu4p35/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved clustered TFLite model to: clustered_quantized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_clustered_model)\n",
        "input_details = interpreter.get_input_details()\n",
        "# interpreter.resize_tensor_input(input_details[0][\"index\"], i1test.shape)\n",
        "interpreter.allocate_tensors()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "#Predictions from TFLite model\n",
        "tfl_pred = []\n",
        "tfl_pred_class = []\n",
        "for i in range(len(x_test)):\n",
        "    interpreter.set_tensor(input_details[0][\"index\"], x_test.astype('int8')[i:i+1,:])\n",
        "    interpreter.invoke()\n",
        "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "    tfl_pred.append(result)\n",
        "    if result > 0:\n",
        "      tfl_pred_class.append(1)\n",
        "    else:\n",
        "      tfl_pred_class.append(0)\n",
        "\n",
        "right_pred = [y_test[i] == tfl_pred_class[i] for i in range(len(y_test))]\n",
        "print(right_pred)\n",
        "acc = sum(right_pred)/len(right_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaBnwbZ4Y1pg",
        "outputId": "2b8fbee2-4d7c-49c4-857b-b368bc1db7c8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, True, True, True, True, True, True, True, False, True, False, False, True, False, True, False, True, True, True, False, True, True, True, True, True, True, False, False, True, False, True, True, True, False, True, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False, True, True, True, False, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, False, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, False, False, False, True, True, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, False, True, True, True, False, False, False, True, False, True, True, True, True, False, False, True, False, True, True, True, True, False, True, True, False, True, True, False, True, True, False, False, True, False, False, True, True, True, True, True, False, True, True, False, True, False, False, True, True, False, False, False, True, False, False, False, False, True, True, True, True, True, True, True, False, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, False, True, False, True, True, False, True, False, True, True, False, True, True, True, True, True, True, False, True, False, True, True, False, False, True, False, True, True, True, True, False, False, True, True, True, False, False, False, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, False, True, True, False, True]\n",
            "0.7077922077922078\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "diabetes_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}